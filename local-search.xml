<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>pytorch&amp;caffe2~深度学习的魔法~使用CINIC-10训练更多网络</title>
    <link href="undefined2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/"/>
    <url>2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/</url>
    
    <content type="html"><![CDATA[<p>上一节我们学习了CNN的基本结构，但是LeNet-5在FashionMNIST数据集上表现也不是非常出色，对于现实生活中更加复杂的图片LeNet-5就更是力不从心了。因此人们提出了更多复杂的卷积神经网络。本节中我们介绍几个经典的设计，分别是进一步加深LeNet-5的AlexNet，串联多个小网络的NiN，和目前大量CNN的基础残差网络ResNet。由于这一节的网络更加强大，为了有区分度我们使用CINIC-10数据集训练。</p><h1 id="cinic-10数据集"><a class="markdownIt-Anchor" href="#cinic-10数据集"></a> CINIC-10数据集</h1><p><a href="https://datashare.is.ed.ac.uk/bitstream/handle/10283/3192/CINIC-10.tar.gz" target="_blank" rel="noopener">CINIC-10</a>是一个CIFAR-10和Imagenet结合的数据集。CIFAR-10是MIT的TinyImages数据集的节选。TinyImages有着8000万张32*32的小图片。由于这个数据集过于庞大，多伦多大学的研究人员从中节选出了和MNIST类似，10个分类，60000张图片的小数据集CIFAR-10。而ImageNet则是另一个庞大的图像数据集，其中包含了超过1400万张的全尺寸图像，并且每一个图像都有对应的分类。由于这两个数据集都是收集了现实生活中的彩色照片，这些数据集相比于MNIST更具有实用性。ImageNet还曾举办CNN界最具竞争性的图像识别大赛ILSVRC，从2010到2017的7届比赛中诞生了很多经典的网络设计。本节中的AlexNet和ResNet便分别是2012和2015届ILSVRC的冠军，而受NiN启发的GoogLeNet则是2014届ILSVRC冠军。</p><p>由于ImageNet规模太大，就算是全部降采样成32*32的图片整个数据集也要有6GB左右，并且降采样后丢失了很多信息。而CIFAR-10如今又显得太小，对于一些复杂的网络来说不够有区分度。因此研究人员就提出了CINIC-10数据集。它是CIFAR-10和ImageNet的结合。爱丁堡大学的研究人员从ImageNet中挑选了和CIFAR-10的分类相关的图像整合在一起，形成了一个有270000张图像的数据集，因此相比CIFAR-10更能区分神经网络的表现，同时没有ImageNet数据集那么庞大，更加容易训练。</p><p>在下载CINIC-10后我们看看里面有什么</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/cinic-10.png" srcset="undefined" class=""><p>可以看到里面有3个文件夹train,test和valid。train和test我们已经接触过很多次了，也就是训练集和测试集。那么valid是什么呢？valid是validate的缩写，也就是验证集。验证集的作用是为我们调参提供参考。上一节讲到神经网络有一些超参数需要我们不断调试使网络达到最佳状态。之前我们直接根据训练集的损失和测试集的准确率来判断我们选择的超参数是不是最优的，但是我们也提到过测试集是绝对不能参与训练过程的，因为它的作用是为神经网络提供一个客观的性能参考。如果我们根据测试集调整超参数，那么相当于测试集也参与到了训练过程中，这样测试集的可参考性就降低了。为了能够在不使用测试集的情况下衡量神经网络的性能，人们提出了验证集的概念。在神经网络训练结束后，我们可以使用验证集先测试一下网络大致的性能，然后根据验证集的准确度调整超参数，在多次测试后选取在验证集上最优的网络放到测试集上测试最终的效果。验证集不一定是一个独立的数据集，由于ImageNet数据量很大，我们可以选择一部分图像作为验证集。而在MNIST这样没有特意分出验证集的数据集上，我们可以使用两种不同的方法分出验证集。一种是直接从训练集中分出一部分（例如10000张图像）用作验证，剩余40000张训练。而另一种被称作K-fold交叉验证法，简单来说就是把50000张图像分成K份（例如10份），每次选择9份训练，剩下一份验证，循环10次后得出一个平均的结果。由于数据集较难收集，这种方法能够更加高效地利用数据集。</p><p>CINIC-10的训练集，测试集和验证集的大小一样，都是90000张图，每个类别有9000张。打开任意一个数据集的文件夹可以看到里面有10个分类，分别是飞机(airplane)，机动车(automobile)，鸟(bird)，猫(cat)，鹿(deer)，狗(dog)，青蛙(frog)，马(horse)，船(ship)和卡车(truck)。这些就是我们训练时要用到的标签了。</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/labels.png" srcset="undefined" class=""><p>接着打开一个标签文件夹，可以看到里面的图片有两类，一类的前缀是cifar10，这些就是属于原来的CIFAR-10的数据集的图片。</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/CINIC-CIFAR-10.png" srcset="undefined" class=""><p>而另一类图片则是有nxxxxxxxx的编号的前缀，这些图片来自ImageNet，而这串数字就是ImageNet的标签编号。</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/CINIC-ImageNet.png" srcset="undefined" class=""><p>我们可以把这串编号输入进ImageNet的官网查询一下。将这串编号放在http://imagenet.stanford.edu/synset?wnid=的wnid=的后面，例如http://imagenet.stanford.edu/synset?wnid=n03335030，打开来就可以看到这个图片对应的类别是战斗机。</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/ImageNet-label.png" srcset="undefined" class=""><p>除了这三个文件夹外，我们还能看到有3个文件，第一个是imagenet-contributors.csv，这个文件里就记录了来自ImageNet的图片的编号，所在的数据集和标签。第二个是README.md，也就是关于这个数据集的一些信息。最后一个是CIFAR-10的分类与ImageNet的对应关系。由于ImageNet的分类比CIFAR-10的分类要细的多，通过这个文件可以找到之间的对应关系。例如CIFAR-10的飞机分类就包含了ImageNet的水上飞机，喷气式飞机，战斗机等多个分类。</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/synsets-to-cifar-10-classes.png" srcset="undefined" class=""><p>由于CINIC-10包含了两个不同数据集的数据，研究人员可以通过这两个文件和文件名提取出两个不同的数据集并进行对比，使这个数据集更加实用。</p><h1 id="使用pytorch加载数据集"><a class="markdownIt-Anchor" href="#使用pytorch加载数据集"></a> 使用pytorch加载数据集</h1><p>由于pytorch没有能自动下载CINIC-10的工具类，我们需要自己将CINIC-10数据集加载进来。当然pytorch已经准备了一个能加载任何图片的数据加载类<code>ImageFolder</code>，它能加载的格式是label/image.png，也正是CINIC-10的格式，因此我们能直接用这个工具类加载CINIC数据集后，再调用DataLoader生成pytorch需要的小批量加载器。</p><pre><code>import torchfrom torchvision import datasets, transformsimage_transforms = transforms.Compose(    [transforms.Resize((128,128)),    transforms.ToTensor(),    transforms.Normalize(mean = [0.47889522, 0.47227842, 0.43047404],                        std = [0.24205776, 0.23828046, 0.25874835])])train_loader = datasets.ImageFolder(&quot;CINIC-10/train&quot;,transform = image_transforms)valid_loader = datasets.ImageFolder(&quot;CINIC-10/valid&quot;, transform = image_transforms)test_loader = datasets.ImageFolder(&quot;CINIC-10/test&quot;, transform = image_transforms)train_loader = torch.utils.data.DataLoader(train, batch_size=200, shuffle=True)valid_loader = torch.utils.data.DataLoader(valid, batch_size=200, shuffle=True)test_loader = torch.utils.data.DataLoader(test, batch_size=200, shuffle=True)</code></pre><p>这里出现了三个新的函数<code>transforms.Compose</code>，<code>transforms.Resize</code>和<code>transforms.Normalize</code>。Compose函数很好理解，它只是将很多个预处理函数串联起来依次执行。而Resize顾名思义是将原来的32*32的图像放大成128*128的图像，这是因为本节的神经网络大多是为ImageNet设计的，本身设计的输入大小很大。为了兼顾训练速度和网络结构我们将它折中放大到128*128。而Normalize函数则是我们没有遇到过的一个新的预处理函数。它的作用是将图像归一化。归一化这个概念其实在手写数字识别网络的caffe2实现里就已经遇到过，只是当时并没有提到这个名词。归一化简单来说就是将图像特征更加集中，便于神经网络训练。在之前训练caffe2时我们做了最简单的归一化，也就是给每个值除以225。因为MNIST的特征已经很集中的出现在中间，所以这样的归一化就足够了。但CINIC-10的图像都是彩色图像，而且特征可能在图像的任何位置，我们需要使用标准化处理(Standarization)。<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>标准化的公式是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{x-\mu}{\sigma}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.199439em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.854439em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">μ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，也就是正态分布算z值的公式。对于彩色图像来说每个通道都需要归一化，因此这里有三个不同的平均值和标准差。这里的平均值和标准差来自README.md。</p><p>读取数据后我们可以用如下代码查看图像</p><pre><code>classes = ('airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck')images, labels = next(iter(train_loader))import numpy as npimport matplotlib.pyplot as plt%matplotlib inlinemean = (0.47889522, 0.47227842, 0.43047404)std = (0.24205776, 0.23828046, 0.25874835)figs,axs = plt.subplots(1,10, figsize=(20, 20)) for ax,i,label in zip(axs,range(0,10),labels):    for t,m,s in zip(images[i],mean,std):        t.mul_(s).add_(m)    ax.imshow(images[i].permute(1,2,0))     ax.set_title(classes[label])     ax.axes.get_xaxis().set_visible(False)    ax.axes.get_yaxis().set_visible(False)</code></pre><p>由于我们在导入数据的时候进行了标准化处理，在使用matplotlib查看图像时要将图像还原成原本的模样。还原的方式也很简单，就是将标准化的操作反过来，也就是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mo>∗</mo><mi>σ</mi><mo>+</mo><mi>μ</mi></mrow><annotation encoding="application/x-tex">x*\sigma+\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span></span></span></span>。同样我们需要在每一个通道上调用pytorch张量的<code>mul_</code>和<code>add_</code>方法还原这个矩阵。像这样名字后带下划线的方法都是就地操作方法，这些方法会直接改变张量本身而不是返回一个新的张量，有助于减少内存使用。由于matplotlib的implot函数显示彩色图像时要求把通道数放在第三维，而pytorch导入的图像通道数通常是在第一维，因此我们使用pytorch张量的<code>permute</code>方法，这个方法可以更换张量各个维的位置，例如<code>image[i].permute(1,2,0)</code>就是将第一维放在最后，第二第三维变成第一第二维。注意pytorch张量的维下标也是从0开始的。最后pytorch会自动将标签转换为一个索引数字，具体哪个数字对应哪个标签可以用数据集的<code>class_to_idx</code>属性确认。例如</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/class_to_idx.png" srcset="undefined" class=""><p>上面使用的classes也正是对应的这个字典写成的。如果不确定自己的数据集对应的索引和上文的classes元组是不是一致，可以使用这个属性查看。在加载好数据集后，我们就可以来构建网络了。</p><h1 id="alexnet"><a class="markdownIt-Anchor" href="#alexnet"></a> AlexNet</h1><p>在上一节中我们发现CNN越深，也就是通道数越多，能够学习到的特征就越多，这也是深度学习名称的由来。AlexNet就是在LeNet的基础上进一步加深了网络结构以增强神经网络的学习能力。首先我们先来看看网络结构。由于网络结构变得越发复杂，从这一节开始我们将只是用表格来说明网络结构。</p><p>AlexNet的主要改进在于增大卷积核和卷积层的深度，并且使用了ReLU作为激活函数（原始的LeNet-5是使用sigmoid函数作为激活函数的，我们在上一节编写的LeNet-5已经做了改进，使用ReLU激活函数）。另外AlexNet还使用了很多图像增广的方法。图像增广是一种扩大数据集的使用方法，通过一些算法对原始的图像做旋转，裁剪等操作使神经网络可以学习到不同位置的同一个特征，让神经网络更加具有普适性。同样在识别图片的时候AlexNet也会翻转图像使神经网络多识别出一些特征，提高正确率。但由于AlexNet的参数数量大大提高，网络很容易过拟合。过拟合简单来说就是神经网络的参数数量已经多到可以“记住”每一张训练集的图片，所以在训练集上可以表现得非常出色，但在测试集上会惨不忍睹。为此，AlexNet引进了DropOut层。DropOut层会在训练时随机丢弃一些参数，使神经网络不会过度依赖一些参数“记住”图像。在测试时为了稳定，DropOut层会被关闭。也就是说使用了DropOut层的神经网络在训练和测试时网络是不一样的。</p><p>为了对比我们暂时先不进行图像增广处理，稍后再增加<code>transforms.CenterCrop</code>，<code>transforms.ColorJitter</code>，<code>transforms.FiveCrop</code>等图像增广函数看看训练效果如何。</p><p>AlexNet的结构如下。原始的AlexNet的输入尺寸是227*227，这里我们将改成128*128适应CINIC-10的大小，同时一些步长和填充参数也有调整。</p><table><thead><tr><th>层名</th><th>输入形状</th><th>输出形状</th><th>步长</th><th>填充</th><th>核/窗口尺寸</th></tr></thead><tbody><tr><td>conv1</td><td>3*128*128</td><td>96*40*40</td><td>3</td><td>0</td><td>11*11</td></tr><tr><td>pool1</td><td>96*40*40</td><td>96*20*20</td><td>2</td><td>0</td><td>2*2</td></tr><tr><td>conv2</td><td>96*20*20</td><td>256*20*20</td><td>1</td><td>2</td><td>5*5</td></tr><tr><td>pool2</td><td>256*20*20</td><td>256*10*10</td><td>2</td><td>0</td><td>2*2</td></tr><tr><td>conv3</td><td>256*10*10</td><td>384*10*10</td><td>1</td><td>1</td><td>3*3</td></tr><tr><td>conv4</td><td>384*10*10</td><td>384*10*10</td><td>1</td><td>1</td><td>3*3</td></tr><tr><td>conv5</td><td>384*10*10</td><td>256*10*10</td><td>1</td><td>1</td><td>3*3</td></tr><tr><td>pool3</td><td>256*10*10</td><td>256*5*5</td><td>2</td><td>0</td><td>2*2</td></tr><tr><td>linear1</td><td>6400</td><td>4096</td><td>N/A</td><td>N/A</td><td>N/A</td></tr><tr><td>dropout1</td><td>4096</td><td>4096</td><td>N/A</td><td>N/A</td><td>N/A</td></tr><tr><td>linear2</td><td>4096</td><td>4096</td><td>N/A</td><td>N/A</td><td>N/A</td></tr><tr><td>dropout2</td><td>4096</td><td>4096</td><td>N/A</td><td>N/A</td><td>N/A</td></tr><tr><td>linear3</td><td>4096</td><td>10</td><td>N/A</td><td>N/A</td><td>N/A</td></tr></tbody></table><p>可以看到AlexNet的通道数和核大小相比LeNet来说都增加了不少。中间的卷积通过填充在不改变图像大小的情况下增加通道数，使神经网络可以学到更多特征。</p><h2 id="使用pytorch构建alexnet"><a class="markdownIt-Anchor" href="#使用pytorch构建alexnet"></a> 使用pytorch构建AlexNet</h2><p>同样我们构建一个类来表示这个网络</p><pre><code>from torch.nn.functional import reluclass AlexNet(torch.nn.Module):    def __init__(self):           super(AlexNet, self).__init__()        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=96, stride=3, kernel_size=11)        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)        self.conv2 = torch.nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2)        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)        self.conv3 = torch.nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)        self.conv4 = torch.nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)        self.conv5 = torch.nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)        self.pool3 = torch.nn.Conv2d(kernel_size=2, stride=2)        self.linear1 = torch.nn.Linear(6400, 4096)        #Dropout层需要有一个超参数p，指的是每个参数被丢弃的概率        self.dropout1 = torch.nn.Dropout(0.5)        self.linear2 = torch.nn.Linear(4096, 4096)        self.dropout2 = torch.nn.Dropout(0.5)        self.linear3 = torch.nn.Linear(4096, 10)                  def forward(self, x):        x = relu(self.conv1(x))          x = self.pool1(x)        x = relu(self.conv2(x))        x = self.pool2(x)        x = relu(self.conv3(x))        x = relu(self.conv4(x))        x = relu(self.conv5(x))        x = self.pool3(x)        x = x.view(-1, 6400)        x = relu(self.linear1(x))        x = self.dropout1(x)        x = relu(self.linear2(x))        x = self.dropout2(x)        x = self.linear3(x)                return x    net = AlexNet()</code></pre><p>我们使用torchsummary和torchviz查看这个网络结构。</p><pre><code>from torchsummary import summary#如果pytorch是否有CUDA支持需要将网络移动到显存中net.to(torch.device(&quot;cuda&quot;))summary(net, (3,128,128))</code></pre><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/AlexNet-arch.png" srcset="undefined" class=""><p>可以看到这个网络有接近四千七百万个参数，相比LeNet的四万多个参数已经大了一百倍。同样，计算图也要大上不少。</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/AlexNet_computational_graph.svg" srcset="undefined" class=""><p>由于我们使用的是ReLU激活函数，初始化方法自然还是He初始化。</p><pre><code>def init_weights(m):    if type(m) == torch.nn.Linear:        torch.nn.init.kaiming_uniform_(m.weight)        m.bias.data.fill_(0.01)    if type(m) == torch.nn.Conv2d:        torch.nn.init.kaiming_uniform_(m.weight)        m.bias.data.fill_(0.01)        net.apply(init_weights)criterion = torch.nn.CrossEntropyLoss()</code></pre><p>最后加上优化函数就可以开始训练了。由于这个网络规模较大，建议使用GPU训练。</p><pre><code>net.to(torch.device(&quot;cuda&quot;))optimizer = torch.optim.Adam(net.parameters(),lr=0.01)for epoch in range(10):    loss = 0    for _, data in enumerate(train_loader):        features, labels = data        features, labels = features.cuda(), labels.cuda()        optimizer.zero_grad()        outputs = net(features)        loss = criterion(outputs,labels)        loss.backward()        optimizer.step()    #每运行完一代就显示训练效果    print(&quot;epoch {}, loss {}&quot;.format(epoch+1,loss.data.item()))</code></pre><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/AlexNet_0.01.png" srcset="undefined" class=""><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/AlexNet_0.01_accuracy.png" srcset="undefined" class=""><p>奇怪和第一次我们使用的CNN结果一样，这次的损失丝毫没有下降，验证集的结果也是惨不忍睹。但我们已经使用了He初始化对权重进行初始化，那么还有什么地方需要调整呢？我们先来看一看和训练过程最相关的超参数：学习率。</p><h3 id="学习率指导模型学习进度"><a class="markdownIt-Anchor" href="#学习率指导模型学习进度"></a> 学习率指导模型学习进度</h3><p>反向传播需要多次更新权重以寻找最小值,而每次更新的幅度对学习成果有重要影响。控制每次更新幅度的参数就是优化算法的学习率。过大的学习率会导致网络错过最低点以至于不能收敛，而过小的学习率又会导致学习过于缓慢。下图可以很形象的表示这两种情况（<a href="https://www.educative.io/edpresso/learning-rate-in-machine-learning" target="_blank" rel="noopener">来源</a>）。</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/learningrate.png" srcset="undefined" class=""><p>由此可见，在一开始我们应该使用较大的学习率，而在最终收敛阶段就需要使用较小的学习率防止网络错过最低点。不同的优化算法对学习率的处理各不相同，早期的算法使用固定的学习率进行更新，而新的算法则会动态降低学习率适应当前的学习情况。例如我们一直使用的Adam算法，全称即为ADAptive Moment estimation 适应性动量估计。事实上Adam算法有四个参数：学习率，beta1，beta2和epsilon用来控制学习率衰减的程度。算法的论文推荐这四个参数分别设置为0.001，0.9，0.999和1e-8，也就是pytorch的默认设置。因此我们也尝试使用这些参数进行训练。</p><p>将<br /><code>optimizer = torch.optim.Adam(net.parameters(),lr=0.01)</code></p><p>改为<br /><code>optimizer = torch.optim.Adam(net.parameters(),lr=0.001)</code></p><p>后，我们得到了更好的训练结果</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/AlexNet_0.001.png" srcset="undefined" class=""><p>我们可以使用验证集确认一下训练的效果</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/AlexNet_0.001_accuracy.png" srcset="undefined" class=""><p>可以看到准确率从随机乱猜的10%已经上升到了49%，效果极为显著。除了Adam算法以外，还有其他自适应学习率的算法，例如AdaDelta，以及使用动量控制学习进度的方法,例如SGD-nesterov，都可以根据学习进度调整更新的幅度。一般来说对于初学者Adam较为合适，而SGD-nesterov在精心调教下可以得到一个更好的结果，所以很多论文依然在用较老的SGD算法。这些优化算法都在pytorch中有官方实现，因此只需替换optimizer便可以体验不同的优化算法。</p><h3 id="使用图像增广扩大数据集"><a class="markdownIt-Anchor" href="#使用图像增广扩大数据集"></a> 使用图像增广扩大数据集</h3><p>在现实生活中，数据集的收集往往是比设计和训练神经网络更加困难的事。因此如何更有效地利用数据便成为了非常重要的研究对象。同时我们也要避免神经网络“记住”训练集的内容，增强它的泛化能力才能以不变应万变。这两个问题都可以通过图像增广改善。AlexNet的成功和它应用了多个图像增广方法密切相关。具体来说，AlexNet使用了三个图像增广方法：裁剪，翻转和随机颜色变化。这些图像增广的工具都包含在torchvision的transforms模块中。AlexNet使用这些方法将数据集扩大了2048倍，这足以显示图像增广可以大幅度提升已有数据的利用率。下面我们修改读取数据集的代码，应用一下这几个函数</p><pre><code>image_transforms = transforms.Compose(    [transforms.Resize((148,148)), #将图片稍稍放大便于裁剪    transforms.RandomHorizontalFlip(p=0.5), #RandomHorizontalFlip随机挑选图片水平翻转，被挑选的几率由p参数控制    transforms.RandomResizedCrop(128), #RandomResizedCrop随机裁剪出图片上的一部分并缩放至需要的大小，缩放的大小由size参数控制，这里我们使用128x128。另外还有其他参数控制裁剪区域的选择与大小控制    transforms.ColorJitter(brightness=0.5,contrast=0.5,saturation=0.5,hue=0.5), #ColorJitter随机调整亮度，对比度，饱和度和色调    transforms.ToTensor(),    transforms.Normalize(mean = [0.47889522, 0.47227842, 0.43047404],                        std = [0.24205776, 0.23828046, 0.25874835])])</code></pre><p>要注意只有训练集需要进行图像增广，而验证集和测试不需要，因此要分成两个函数处理。处理完毕后我们看一看处理的成果</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/augmentation.png" srcset="undefined" class=""><p>可以看到相比一开始有些图片已经被很明显的处理过了。我们使用这个新的数据集进行训练。要注意的是pytorch并不会直接增大数据集大小，这些处理是在训练途中进行的。如果觉得由于图像增广训练缓慢可以试试<a href="https://github.com/albumentations-team/albumentations" target="_blank" rel="noopener">albumentations</a>这类库提前处理图像增广再训练。由于数据增广后难度增加，我们使用一个较小的学习率0.0001训练。</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/augmentation_train.png" srcset="undefined" class=""><p>使用验证集和测试集检查训练结果，可以发现识别率又上升了12%左右，说明图像增广可以有效提升神经网络泛化的能力。</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/augmentation_valid.png" srcset="undefined" class=""><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/augmentation_test.png" srcset="undefined" class=""><h2 id="使用caffe2构建alexnet"><a class="markdownIt-Anchor" href="#使用caffe2构建alexnet"></a> 使用caffe2构建AlexNet</h2><p>由于caffe2并没有提供CINIC-10的数据集，我们首先要自己构建数据集。这里我们参照caffe2的<a href="https://github.com/facebookarchive/tutorials/blob/master/CIFAR10_Part1.ipynb" target="_blank" rel="noopener">官方教程</a>构建。</p><p>在pytorch中，框架会自动将文件夹名作为标签导入，并为每一个标签赋一个数字索引。然而caffe2并不会自动完成这些工作，因此第一步就是要为每一个标签创建索引，并使用在caffe中很常用的标签文件将图片和分类索引挂钩。例如我们的索引是<code>{'airplane': 0,'automobile': 1,'bird': 2,'cat': 3,'deer': 4,'dog': 5,'frog': 6,'horse': 7,'ship': 8,'truck': 9}</code>，那标签文件就是</p><pre><code>CINIC-10/train/airplane/cifar10-train-29.png 0CINIC-10/train/automobile/cifar10-train-4.png 1CINIC-10/train/bird/cifar10-train-6.png 2...</code></pre><p>以此类推，为训练集，验证集和测试集分别创建标签文件。不同的数据集标签的方法不同，因此创建标签文件的代码自然也不同。这里我们根据CINIC-10的标签创建这一文件。</p><pre><code>import ostrain_dataset_path = &quot;CINIC-10/train&quot;test_dataset_path = &quot;CINIC-10/test&quot;valid_dataset_path = &quot;CINIC-10/valid&quot;labels = os.listdir(train_dataset_path) #CINIC-10的标签是每个子文件夹的名字，因此只需用os.listdir便可读取所有标签classes = {label:index for index,label in enumerate(labels)} #使用数组下标作为索引</code></pre><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/caffe2_classes.png" srcset="undefined" class=""><p>准备好索引后我们就可以创建标签文件了</p><pre><code>train_label_file_path = &quot;CINIC-10/train-labels.txt&quot;test_label_file_path = &quot;CINIC-10/test-labels.txt&quot;valid_label_file_path = &quot;CINIC-10/valid-labels.txt&quot;from random import shufflewith open(train_label_file_path,'w') as f:    train_files = []    for root,dir,file in os.walk(train_dataset_path):        root = root.replace(&quot;\\&quot;,&quot;/&quot;) #在windows中路径分隔符是\，为了统一全部换成/        label = root.split(&quot;/&quot;)[-1] #路径的最后一个文件夹名即为标签名，因此将它提取出        #使用一个列表生成式生成文件的每一行并用writelines填充文件        train_files.extend([&quot;{root}/{filename} {clsindex}\n&quot;.format(root=root,filename=fn,clsindex=classes[label]) for fn in file])    #打乱图像的顺序    shuffle(train_files)    f.writelines(train_files)#以此类推生成验证集和测试集的标签文件with open(test_label_file_path,'w') as f:    test_files= []    for root,dir,file in os.walk(test_dataset_path):        root = root.replace(&quot;\\&quot;,&quot;/&quot;)        label = root.split(&quot;/&quot;)[-1]         test_files.extend([&quot;{root}/{filename} {clsindex}\n&quot;.format(root=root,filename=fn,clsindex=classes[label]) for fn in file])    shuffle(test_files)    f.writelines(test_files)        with open(valid_label_file_path,'w') as f:    valid_files = []    for root,dir,file in os.walk(valid_dataset_path):        root = root.replace(&quot;\\&quot;,&quot;/&quot;)        label = root.split(&quot;/&quot;)[-1]         valid_files.extend([&quot;{root}/{filename} {clsindex}\n&quot;.format(root=root,filename=fn,clsindex=classes[label]) for fn in file])    shuffle(valid_files)    f.writelines(valid_files)</code></pre><p>接下来打开训练用标签文件检查是否正确生成</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/label_files.png" srcset="undefined" class=""><h3 id="使用albumentations进行图像增广"><a class="markdownIt-Anchor" href="#使用albumentations进行图像增广"></a> 使用albumentations进行图像增广</h3><p>在写入数据库前，首先我们需要考虑图像增广。由于caffe2的图像增广功能依赖OpenCV，而OpenCV编译也需要大量时间，因此在安装pytorch时我们默认没有安装OpenCV支持。因此我们使用之前介绍的图像增广库<a href="https://github.com/albumentations-team/albumentations" target="_blank" rel="noopener">albumentations</a>先生成增广后的图片再制作数据集。如果已经安装OpenCV支持可以跳过这一段，直接构建数据集，在之后导入时我会同时演示这两种方法对应的导入代码。</p><p>albumentations是一个功能齐全的图像增广库，可以对图像进行变色，翻转，扭曲，遮罩等多种处理。这里我们只使用和pytorch相同的翻转，裁剪和变色三种方法。首先安装albumentation：</p><pre><code>conda install -c conda-forge imgaugconda install albumentations -c conda-forge</code></pre><p>albumentations有着和pytorch相似的API，因此很容易上手。我们先用一张图片尝试尝试</p><pre><code>import albumentations as Afrom imageio import imreadimport matplotlib.pyplot as plt%matplotlib inlinemean = (0.47889522, 0.47227842, 0.43047404)std = (0.24205776, 0.23828046, 0.25874835)img = imread(&quot;CINIC-10/train/airplane/cifar10-train-29.png&quot;)aug = A.Compose([    A.Resize(width=148,height=148),    A.HorizontalFlip (p=0.5),    A.RandomResizedCrop(width=128,height=128),    A.ColorJitter(brightness=0.5,contrast=0.5,saturation=0.5,hue=0.5),    A.Normalize(mean=mean,std=std)],p=1)aug_img = aug(image=img)figs,axs = plt.subplots(1,2, figsize=(20,20)) aug_img['image'] *= stdaug_img['image'] += meanaxs[0].imshow(img)axs[1].imshow(aug_img['image']){% asset_img albumentation_test.png %}</code></pre><p>可以看到图片已经经过了一定的处理。接下来我们将这个函数融入下面的<code>write_lmdb</code>中创建数据集。</p><p>标签文件制作完成后我们就可以根据这个文件制作lmdb或leveldb数据库供caffe2使用了，下面这个函数改编自官方教程的write_lmdb函数。除了能够写入caffe2的ImageInput能直接读取的图像格式以外，我们还增加了和图像增广有关的函数。为了方便我们直接将原始的数据集和增广后的数据集一起写入数据库中。</p><pre><code>import lmdbimport numpy as npfrom caffe2.proto import caffe2_pb2from imageio import imreaddef write_lmdb(labels_file_path, lmdb_path, augmentation=False,is_test=False,mean=[],std=[]):    with open(labels_file_path, 'r') as labels_handler:        print(&quot;&gt;&gt;&gt; Write database...&quot;)        if augmentation is False:            LMDB_MAP_SIZE = 1 &lt;&lt; 31 # map size代表LMDB能够达到最大的大小，默认为1&lt;&lt;40，即1TB。在某些系统上这会导致系统直接分配1TB空间而不是使用稀疏文件表示。                                # 因此我们设置为一个贴近数据集的大小1&lt;&lt;31，即2GB        else:            LMDB_MAP_SIZE = 1 &lt;&lt; 35 #使用albumentations进行数据增广时数据集大小会变成17GB，因此将大小设置为1&lt;&lt;35，即32GB        env = lmdb.open(lmdb_path, map_size=LMDB_MAP_SIZE)        with env.begin(write=True) as txn:            count = 0            for line in labels_handler.readlines(): # 从标签文件中读取每一行                line = line.rstrip()                im_path = line.split()[0] # 标签文件第一部分是文件名，第二部分是分类索引                im_label = int(line.split()[1])                if augmentation is True:                    from imageio import imread                    img_data = imread(im_path).astype(np.float32) # 使用imageio库读取图片并转换为numpy数组，默认读取的格式是HWC，即(高,宽,通道)                else:                                             # 彩色图片有三个通道，即RGB                    from cv2 import imread,IMREAD_UNCHANGED #如果使用ImageInput则使用cv2读取数据，OpenCV默认读取为BGR格式，和caffe2一致                    img_data = imread(im_path,IMREAD_UNCHANGED) # caffe2的ImageInput接受原始图像输入，因此使用cv2的imread和tobytes转换为字节字符串。IMREAD_UNCHANGED阻止OpenCV将灰度图转成彩色图                    im_bytes = img_data.tobytes()                if len(img_data.shape) == 3: #在CINIC-10中有大约100多张灰度图（没有通道维），为了方便处理我们只使用彩色图                      if augmentation is True:                        normalization = A.Compose([                            A.Normalize(mean=mean,std=std),                            A.Resize(width=128,height=128)],p=1) #如果使用图像增广则原始图像使用albumentation归一化                        img_data = normalization(image=img_data)['image']                        img_data = img_data[:, :, (2, 1, 0)] # caffe2沿用caffe的BGR格式，因此要将RGB三个通道调换位置，这是由于caffe使用OpenCV处理图像                                                            # 而OpenCV使用BGR表示图像                        img_data = np.transpose(img_data, (2,0,1)) # 将HWC转换为CHW，即(通道,高,宽)，这么做是为了能够使用GPU加速。Nvidia的cuDNN库只支持CHW格式                                                                # 之前MNIST数据集使用NCHW也是源于此，N为每一个小批量的大小                    # 将图像存储在caffe2张量中，每个tensor_protos存储两个张量，即图像本身和标签                    tensor_protos = caffe2_pb2.TensorProtos()                    img_tensor = tensor_protos.protos.add()                     img_tensor.dims.extend(img_data.shape)                     if augmentation is True:                        img_tensor.data_type = 1 # data_type对应caffe2的DataType枚举，1代表float                        flatten_img = img_data.reshape(np.prod(img_data.shape))                        img_tensor.float_data.extend(flatten_img)                    else:                        img_tensor.data_type = 3 #如果使用caffe2自带的ImageInput处理图像则将data_type设为3，即byte                        img_tensor.byte_data = im_bytes                    label_tensor = tensor_protos.protos.add()                     label_tensor.data_type = 2 #2代表int32                    label_tensor.int32_data.append(im_label)                    txn.put(                        '{}'.format(count).encode('ascii'), #lmdb是键值数据库，键为当前处理图像的编号                        tensor_protos.SerializeToString() #值即为两个张量                    )                    count = count + 1                    # 执行图像增广并制作张量 如果是在制作测试数据集则跳过增广                    if augmentation is True and is_test is False:                        img_data = imread(im_path).astype(np.float32)                        aug = A.Compose([                            A.Resize(width=148,height=148),                            A.HorizontalFlip (p=0.5),                            A.RandomResizedCrop(width=128,height=128),                            A.ColorJitter(brightness=0.5,contrast=0.5,saturation=0.5,hue=0.5),                            A.Normalize(mean=mean,std=std)                        ],p=1)                        aug_img_data = aug(image=img_data)['image']                        aug_img_data = aug_img_data[:, :, (2, 1 ,0)]                        aug_img_data = np.transpose(aug_img_data,(2,0,1))                        aug_tensor_protos = caffe2_pb2.TensorProtos()                        aug_img_tensor = aug_tensor_protos.protos.add()                         aug_img_tensor.dims.extend(aug_img_data.shape)                         aug_img_tensor.data_type = 1                        aug_flatten_img = aug_img_data.reshape(np.prod(aug_img_data.shape))                        aug_img_tensor.float_data.extend(aug_flatten_img)                        aug_label_tensor = aug_tensor_protos.protos.add()                         aug_label_tensor.data_type = 2                        aug_label_tensor.int32_data.append(im_label)                        count = count + 1                        txn.put(                            '{}'.format(count).encode('ascii'),                             aug_tensor_protos.SerializeToString()                        )                    if ((count % 1000 == 0)):                        print(&quot;Inserted {} rows&quot;.format(count))    print(&quot;Inserted {} rows&quot;.format(count))    print(&quot;\nLMDB saved at &quot; + lmdb_path + &quot;\n\n&quot;)</code></pre><p>要注意这里data_type属性和caffe2的DataType对应，具体的关系是</p><pre><code>enum DataType { UNDEFINED = 0; FLOAT = 1;  // float INT32 = 2;  // int BYTE = 3;  // BYTE, when deserialized, is going to be restored as uint8. STRING = 4;  // string BOOL = 5;  // bool UINT8 = 6;  // uint8_t INT8 = 7;  // int8_t UINT16 = 8;  // uint16_t INT16 = 9;  // int16_t INT64 = 10;  // int64_t FLOAT16 = 12;  // at::Half DOUBLE = 13;  // double}</code></pre><p>如果需要不同的数据类型可以通过修改这个值实现。LevelDB除了用于读写的库不同其他都相同，因此不再赘述。接下来便可直接使用该函数创建数据库</p><pre><code>train_lmdb_path = &quot;CINIC-10/train.db&quot;test_lmdb_path = &quot;CINIC-10/test.db&quot;valid_lmdb_path = &quot;CINIC-10/valid.db&quot;mean = (0.47889522, 0.47227842, 0.43047404)std = (0.24205776, 0.23828046, 0.25874835)# 如需要使用albumentation进行图像增广write_lmdb(train_label_file_path,train_lmdb_path,augmentation=True,mean=mean,std=std)write_lmdb(test_label_file_path,test_lmdb_path,augmentation=True,is_test=True,mean=mean,std=std)write_lmdb(valid_label_file_path,valid_lmdb_path,augmentation=True,is_test=True,mean=mean,std=std)# 如需要使用caffe2自带的图像增广功能write_lmdb(train_label_file_path,train_lmdb_path)write_lmdb(test_label_file_path,test_lmdb_path)write_lmdb(valid_label_file_path,valid_lmdb_path)</code></pre><p>使用训练集测试函数是否正常运作，这里不使用图像增广</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/lmdb_train.png" srcset="undefined" class=""><p>可以看到成功向数据库中写了89895张图片，由于我们剔除了灰度图，训练集比CINIC-10原本包含的90000张图少了一些，但对训练没有什么影响。同样我们可以制作出验证集和测试集的数据库。如果使用图像增广</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/albumentation_train_set.png" srcset="undefined" class=""><p>可以看到写入的数据量多了一倍，也就是说数据集现在同时包含原始图像和增广后的图像</p><p>数据库制作好后，我们就可以开始构建网络了。如果之前使用albumentation制作图像增广，载入数据库的代码与之前基本一致。由于我们在写入数据库时已经做了归一化，原本用于简易归一化的Scale操作符和转换数据类型的Cast操作符也不需要了。</p><pre><code>with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)): #由于CINIC-10数据集较大，我们使用CUDA训练，如没有支持CUDA的显卡则删去这行    from caffe2.python import brew, core, model_helper, optimizer, workspace, net_drawer    train_model = model_helper.ModelHelper(&quot;train_model&quot;,arg_scope={&quot;order&quot;:&quot;NCHW&quot;})    features, labels = train_model.TensorProtosDBInput([],[&quot;features&quot;,&quot;labels&quot;],batch_size=50,db=&quot;CINIC-10/train_aug.db&quot;,db_type=&quot;lmdb&quot;)    features = train_model.StopGradient(features,features)</code></pre><p>如果在编译pytorch时已经编译了OpenCV2支持，可以使用一个新的操作符<a href="https://caffe2.ai/docs/operators-catalogue.html#imageinput" target="_blank" rel="noopener">ImageInput</a>取代直接读取张量的TensorProtosDBInput。ImageInput自带图像增广方法，只需将参数传入即可调用。同样删去用于归一化的<code>features = train_model.Scale(features,features,scale=float(1/256))</code>。brew也为ImageInput提供了一个简单的包装，这里使用brew.image_input调用该操作符。</p><pre><code>with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)):    from caffe2.python import brew, core, model_helper, optimizer, workspace, net_drawer    train_model = model_helper.ModelHelper(&quot;train_model&quot;,arg_scope={&quot;order&quot;:&quot;NCHW&quot;})    features, labels = brew.image_input(train_model,train_reader,[&quot;features&quot;,&quot;labels&quot;],                                                        color=3,color_jitter=1,                                                        mirror=1,scale=224,                                                        crop=128,                                                        mean_per_channel=tuple((x*256 for x in (0.43047404,0.47227842,0.47889522))),#ImageInput的平均值和标准差取值范围是0-256而不是0-1，因此需要转换一下                                                        std_per_channel=tuple((x*256 for x in (0.25874835,0.23828046,0.24205776))),                                                        use_caffe_datum=False,use_gpu_transform=1, #如果有CUDA则设置use_gpu_transform=1，ImageInput会自动将图像转为NCHW。                                                        is_test=False,batch_size=50)    features = train_model.net.NHWC2NCHW(features,&quot;features_nchw&quot;) #如没有CUDA设备则调用NHWC2NCHW操作符转换    features = train_model.StopGradient(features,features)</code></pre><p>接下来只需将AlexNet在caffe2中写一遍</p><pre><code>with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)):    conv1 = brew.conv(train_model, features, &quot;conv1&quot;,dim_in=3,dim_out=96,weight_init=(&quot;MSRAFill&quot;,{}),kernel=11,stride=3)    relu1 = brew.relu(train_model, conv1, &quot;relu1&quot;)    pool1 = brew.max_pool(train_model, relu1, &quot;pool1&quot;,kernel=2,stride=2)    conv2 = brew.conv(train_model, pool1, &quot;conv2&quot;, dim_in=96,dim_out=256, weight_init=(&quot;MSRAFill&quot;,{}),kernel=5,pad=2)    relu2 = brew.relu(train_model,conv2,&quot;relu2&quot;)    pool2 = brew.max_pool(train_model,relu2,&quot;pool2&quot;,kernel=2,stride=2)    conv3 = brew.conv(train_model, pool2, &quot;conv3&quot;, dim_in=256,dim_out=384, weight_init=(&quot;MSRAFill&quot;,{}),kernel=3,pad=1)    relu3 = brew.relu(train_model,conv3,&quot;relu3&quot;)    conv4 = brew.conv(train_model, relu3, &quot;conv4&quot;, dim_in=384,dim_out=384, weight_init=(&quot;MSRAFill&quot;,{}),kernel=3,pad=1)    relu4 = brew.relu(train_model,conv4,&quot;relu4&quot;)    conv5 = brew.conv(train_model, relu4, &quot;conv5&quot;, dim_in=384,dim_out=256, weight_init=(&quot;MSRAFill&quot;,{}),kernel=3,pad=1)    relu5 = brew.relu(train_model,conv5,&quot;relu5&quot;)    pool3 = brew.max_pool(train_model,relu5,&quot;pool3&quot;,kernel=2,stride=2)    fc1 = brew.fc(train_model,pool3,&quot;fc1&quot;,dim_in=256*5*5,dim_out=4096,weight_init=(&quot;MSRAFill&quot;,{}))    relu6 = brew.relu(train_model,fc1,&quot;relu6&quot;)    dropout1 = brew.dropout(train_model, relu6, &quot;dropout1&quot;, ratio=0.5，is_test=False)    fc2 = brew.fc(train_model,dropout1,&quot;fc2&quot;,dim_in=4096,dim_out=4096,weight_init=(&quot;MSRAFill&quot;,{}))    relu7 = brew.relu(train_model,fc2,&quot;relu7&quot;)    dropout2 = brew.dropout(train_model,relu7,&quot;dropout2&quot;,ratio=0.5,is_test=False)    fc3 = brew.fc(train_model,dropout2,&quot;fc3&quot;,dim_in=4096,dim_out=10,weight_init=(&quot;MSRAFill&quot;,{}))    softmax = brew.softmax(train_model,fc3,&quot;softmax&quot;)</code></pre><p>加入交叉熵函数</p><pre><code>with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)):    crossEntropy = train_model.LabelCrossEntropy([softmax,labels],&quot;crossEntropy&quot;)    loss = train_model.AveragedLoss(crossEntropy, &quot;loss&quot;)</code></pre><p>确认计算图</p><pre><code>from IPython import displaygraph = net_drawer.GetPydotGraph(train_model.Proto().op,&quot;train&quot;,rankdir=&quot;LR&quot;)display.Image(graph.create_png(),width=800)</code></pre><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/alexmap_graph.png" srcset="undefined" class=""><p>加入优化算法，学习率设为0.0001</p><pre><code>with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)):    train_model.AddGradientOperators([loss])    optimizer.build_adam(        train_model,        base_learning_rate=0.0001,        policy=&quot;step&quot;,        stepsize=1,        gamma=0.999,    )</code></pre><p>每个小批量大小为50，我们需要迭代10代。如使用albumentation增广，训练集大小为179790，即循环35958次。如果使用caffe2的ImageInput在运行时处理图像训练集大小不变，即89895张图片，循环17979次。我们这里使用ImageInput处理图像，因此设置循环17979次。</p><pre><code>workspace.RunNetOnce(train_model.param_init_net)workspace.CreateNet(train_model.net)total_iters = 17979loss = [0 for i in range(17979)]for i in range(total_iters):workspace.RunNet(train_model.net.Proto().name)loss[i] = workspace.FetchBlob('loss')    if i%1000 == 0:        print(&quot;Current loss: {}&quot;.format(loss))print(loss)</code></pre><p>使用Albumentations的loss如下</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/albumentations_loss.png" srcset="undefined" class=""><p>使用ImageInput的loss如下</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/ImageInput_loss.png" srcset="undefined" class=""><p>接下来使用训练集和测试集检验结果。为了方便我将验证集用于ImageInput，测试集用于Albumentations。</p><pre><code>with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):    test_model = model_helper.ModelHelper(&quot;test_model&quot;,arg_scope={&quot;order&quot;:&quot;NCHW&quot;},init_params=False)    #使用ImageInput    valid_reader = test_model.CreateDB(&quot;valid_reader&quot;,db_type=&quot;lmdb&quot;,db=&quot;CINIC-10/valid.db&quot;,num_shards=1,shard_id=0)    features, labels = brew.image_input(test_model,valid_reader,[&quot;features&quot;,&quot;labels&quot;],                                                        color=3,color_jitter=0, #关闭图像增广参数                                                        mirror=0,scale=128,                                                        crop=128,                                                        mean_per_channel=tuple((x*256 for x in (0.43047404,0.47227842,0.47889522))),                                                        std_per_channel=tuple((x*256 for x in (0.25874835,0.23828046,0.24205776))),                                                        use_caffe_datum=False,use_gpu_transform=1,                                                         is_test=True,batch_size=200) #设置is_test启用测试模式    #使用Albumentations    #features, labels = test_model.TensorProtosDBInput([],[&quot;features&quot;,&quot;labels&quot;],batch_size=200,db=&quot;CINIC-10/test.db&quot;,db_type=&quot;lmdb&quot;)    features = test_model.StopGradient(features,features)    conv1 = brew.conv(test_model, features, &quot;conv1&quot;,dim_in=3,dim_out=96,kernel=11,stride=3)    relu1 = brew.relu(test_model, conv1, &quot;relu1&quot;)    pool1 = brew.max_pool(test_model, relu1, &quot;pool1&quot;,kernel=2,stride=2)    conv2 = brew.conv(test_model, pool1, &quot;conv2&quot;, dim_in=96,dim_out=256,kernel=5,pad=2)    relu2 = brew.relu(test_model,conv2,&quot;relu2&quot;)    pool2 = brew.max_pool(test_model,relu2,&quot;pool2&quot;,kernel=2,stride=2)    conv3 = brew.conv(test_model, pool2, &quot;conv3&quot;, dim_in=256,dim_out=384,kernel=3,pad=1)    relu3 = brew.relu(test_model,conv3,&quot;relu3&quot;)    conv4 = brew.conv(test_model, relu3, &quot;conv4&quot;, dim_in=384,dim_out=384,kernel=3,pad=1)    relu4 = brew.relu(test_model,conv4,&quot;relu4&quot;)    conv5 = brew.conv(test_model, relu4, &quot;conv5&quot;, dim_in=384,dim_out=256,kernel=3,pad=1)    relu5 = brew.relu(test_model,conv5,&quot;relu5&quot;)    pool3 = brew.max_pool(test_model,relu5,&quot;pool3&quot;,kernel=2,stride=2)    fc1 = brew.fc(test_model,pool3,&quot;fc1&quot;,dim_in=256*5*5,dim_out=4096)    relu6 = brew.relu(test_model,fc1,&quot;relu6&quot;)    dropout1 = brew.dropout(test_model, relu6, &quot;dropout1&quot;, ratio=0.5,is_test=True)    fc2 = brew.fc(test_model,dropout1,&quot;fc2&quot;,dim_in=4096,dim_out=4096)    relu7 = brew.relu(test_model,fc2,&quot;relu7&quot;)    dropout2 = brew.dropout(test_model,relu7,&quot;dropout2&quot;,ratio=0.5,is_test=True)    fc3 = brew.fc(test_model,dropout2,&quot;fc3&quot;,dim_in=4096,dim_out=10)    softmax = brew.softmax(test_model,fc3,&quot;softmax&quot;)    accuracy = brew.accuracy(test_model, [softmax,labels],&quot;accuracy&quot;)</code></pre><p>Albumentations的结果如下</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/albumentations_accuracy.png" srcset="undefined" class=""><p>ImageInput的结果如下</p><img src="/2020/05/02/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E4%BD%BF%E7%94%A8CINIC-10%E8%AE%AD%E7%BB%83AlexNet/ImageInput_accuracy.png" srcset="undefined" class=""><p>至此我们迈出了深度卷积神经网络的第一步————AlexNet。下面我们还会继续认识另外两个对卷积神经网络的改进网络结构：NiN和ResNet。</p><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>Normalization这个词可以翻译成正规化，标准化，归一化等，是一个较大的概念，指的是几种特征缩放(Feature Scaling)的方法。包括min-max归一化(min-max normalization)，均值归一化(mean normalization)和标准化(standarization)。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <categories>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>caffe2</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch&amp;caffe2 深度学习的魔法 CNN与图片分类网络</title>
    <link href="undefined2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/"/>
    <url>2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<p>尽管一个能够识别手写数字的神经网络是非常有趣，但它的使用范围非常有限：只能识别数字，输入的数字必须是28*28的单通道灰度图像，而且识别准确率也并不是很高。出现这样的问题一部分原因是多层感知机的参数过多。假如要识别一张500万像素的图片，那么就需要至少500万个神经元放在输入层，而每一个神经元都需要连接到隐藏层中的神经元，导致整个神经网络计算复杂度过高，且大量的参数使梯度下降十分难进行，神经网络几乎不能收敛。另一方面，输入层的尺寸固定导致神经网络的可扩展性有限。因此，为了识别尺寸更大的图片人们提出了一种新的网络结构：卷积神经网络(Convolutional Neural Network, CNN)。</p><h1 id="卷积神经网络"><a class="markdownIt-Anchor" href="#卷积神经网络"></a> 卷积神经网络</h1><p>卷积神经网络中的卷积卷积是一个数学分析的概念，而神经网络中的卷积则指的是一种更加简单的运算：互相关运算。卷积的本质由于涉及到高等数学的知识在此不做讨论，我们只需了解神经网络中它是用来做什么的以及如何运算。</p><p>在卷积神经网络中有多种不同的层结构，最基本的包括包括卷积层，池化层和全连接层。这种网络结构是受猫的大脑结构的启发。猫的大脑在处理图像时会对图像进行加工，只提取出最重要的部分，使猫能够对环境快速反应。科学家因此设计出了卷积层。卷积层通过卷积核提取图像中最重要的特征，并去除不重要的像素以减少复杂度。卷积核是一个非常小的矩阵，通常尺寸是3*3，5*5或7*7，整个卷积层只需要训练一个卷积核就可以提取图像的特征，而且不受输入图像尺寸的影响，因此参数数量可以大大减少。下面以一个2*2的卷积核应用于一个3*3的输入图像举例卷积核是如何工作的。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnalign="left left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>9</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>6</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>8</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>5</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>7</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>8</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>4</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>6</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\left[\begin{array}{cc}  1 &amp; 0\\  1 &amp; 0\\\end{array}\right] \left[\begin{array}{lll} 9 &amp; 6 &amp; 8 \\5 &amp; 7 &amp; 8 \\4 &amp; 6 &amp; 1 \\\end{array}\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.60004em;vertical-align:-1.55002em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">9</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">5</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">6</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">7</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">6</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">8</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">8</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>首先我们将卷积核放在左上角，然后计算卷积，即将对应位置上的数相乘然后相加，也就是1*9+0*6+1*5+0*7=14，因此输出矩阵的第一个值就是14。接下来将卷积核向右移动一格，计算出1*6+0*8+1*7+0*8=13。以此类推我们得出一个新的矩阵：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>14</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>13</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>9</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>13</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><annotation encoding="application/x-tex">\left[\begin{array}{cc}14 &amp; 13 \\ 9 &amp; 13 \\\end{array}\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">4</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">9</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">3</span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span></span></span></span></p><p>仅需要一个卷积核，我们便可以得到一个比原图像小的多的矩阵，并且这个矩阵提取了原图像中最重要的信息（假设卷积核训练效果良好），大大减少了需要的计算量。 如果一个卷积层中有两个以上的输入通道，那么卷积层中就会有对应数量的卷积核，每个通道都会和对应的卷积核进行互相关操作，得到的新矩阵会相加后输出。例如一个两通道的输入，那么就会有两个卷积核，每一个卷积核对应一个通道，得到两个不同的矩阵后相加输出。</p><p>由此可见，不管输入几个通道卷积层默认都只输出一个通道，那么如果要输出多个通道怎么办呢？只需要给卷积核增加通道就可以了。例如一个有两个输入，核的尺寸为2卷积层卷积核的形状是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mo>∗</mo><mn>2</mn><mo>∗</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2*2*2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>，按照上述的计算方法最后只会有一个通道输出。因此如果想要有两个通道输出就得在每个输出通道上有两个卷积核，让卷积核的形状为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mo>∗</mo><mn>2</mn><mo>∗</mo><mn>2</mn><mo>∗</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2*2*2*2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>。这里的顺序是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><msub><mi>t</mi><mi>c</mi></msub><mi>h</mi><mi>a</mi><mi>n</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>s</mi><mo>∗</mo><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><msub><mi>t</mi><mi>c</mi></msub><mi>h</mi><mi>a</mi><mi>n</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>s</mi><mo>∗</mo><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><msub><mi>l</mi><mi>h</mi></msub><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>∗</mo><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><msub><mi>l</mi><mi>w</mi></msub><mi>i</mi><mi>d</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">output_channels*input_channels*kernel_height*kernel_width</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mord mathdefault">p</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">h</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">p</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">h</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">e</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">h</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span></span></span></span>。这样在进行互相关运算时会先调用第1组卷积核为两个通道进行互相关运算得出一个新的矩阵，然后再调用第二组卷积核计算出另一个矩阵，然后将这两个矩阵连结成新的两个通道输出，就得到了有多个输出通道的卷积层。</p><p>一般来说卷积层后会有一个池化层，它的工作方式和卷积层差不多，有一个类似卷积核的池化窗口，但是它只会选择最大的一个数值或平均所有数值输出。上述例子中的矩阵经过一个2*2最大池化层时只有14会被输出而经过平均池化层则会只有12.25被输出。池化层的用途是减少卷积层对位置的敏感性。例如我们设计了一个提取边缘的神经网络，但在图像上边缘往往不会只有一两个像素宽，并且会在图像的各个角落出现，因此卷积层可能会在不同位置提取出大量重复的边缘特征。池化层通过提取最大值减少了这种重复的特征，提高神经网络的准确性。</p><p>我们可以发现卷积核和池化窗口的尺寸会直接影响卷积神经网络的性能。过大的卷积核不容易训练，而过小则会导致神经网络不能充分学习，因此卷积核和池化窗口的尺寸需要慎重选择。像这样需要人调整的神经网络参数被称作超参数，也就是计算机本身不能自己学习的参数。除了卷积核和池化窗口尺寸以外，卷积神经网络还有两个重要的超参数：填充(padding)和步长(stride)。当一张图像比神经网络输入层尺寸小或者我们需要让卷积层输入输出尺寸一样时，就需要人为地使图像尺寸增大，这个操作称为填充。在默认情况下，我们会让卷积核一次移动一个像素，但卷积核也可以一次移动更多个像素，而每一次卷积核要移动的距离则由步长来定义。要注意的是池化窗口一般情况下步长和池化窗口尺寸一致，例如一个2*2的池化窗口一般情况下会一次移动两个像素，因此每个池化窗口不会重叠，可以更高效地完成池化操作。</p><p>一个典型的卷积神经网络会有多个卷积层和池化层交替放置在减少输入尺寸的同时突出特征。卷积层和池化层提取图像特征后，这些特征将输入最后的全连接层进行实际的识别。此时进入全连接层的特征图像相当于是原图的精华。尽管全连接层的输入尺寸依旧是固定的，卷积层提取出的特征可以帮助全连接层更快地学习到识别图像需要的特征同时大大降低了计算的复杂度。</p><p>为了缩短训练时间我们使用MNIST的变种FashionMNIST来训练一个卷积神经网络。但卷积神经网络可以适应更大的图片，在下一节我们将使用<a href="https://datashare.is.ed.ac.uk/bitstream/handle/10283/3192/CINIC-10.tar.gz" target="_blank" rel="noopener">CINIC-10</a>训练一个更加强大的分类网络。</p><h1 id="使用pytorch构建网络"><a class="markdownIt-Anchor" href="#使用pytorch构建网络"></a> 使用pytorch构建网络</h1><h2 id="下载fashionmnist数据集"><a class="markdownIt-Anchor" href="#下载fashionmnist数据集"></a> 下载FashionMNIST数据集</h2><p>下载FashionMNIST数据集步骤和MNIST类似，只需要将所有的MNIST改成FashionMNIST</p><pre><code>import torchfrom torchvision import datasetsfrom torchvision import transforms#datasets.MNIST(加载路径，是否使用训练集（设为False导入测试集），#文件不存在下载，数据集预处理函数）train_loader = torch.utils.data.DataLoader(datasets.FashionMNIST('./FashionMNIST', train=True, download=True,transform=transforms.ToTensor()),batch_size=50, shuffle=True)test_loader =  torch.utils.data.DataLoader(    datasets.FashionMNIST('./FashionMNIST', train=False, download=True,transform=transforms.ToTensor()),    batch_size=50, shuffle=True)</code></pre><p>使用同样的方法查看一下数据集的大小</p><pre><code>images, labels = next(iter(train_loader))images.size(),labels.size()</code></pre><p>FashionMNIST数据集和MNIST是完全兼容的数据集，因此图像集和标签的大小和MNIST是一模一样的。</p><p>用同样的代码查看一下前十张图</p><pre><code>import matplotlib.pyplot as plt%matplotlib inlinefigs,axs = plt.subplots(1,10, figsize=(20, 20)) for ax,i,label in zip(axs,range(0,10),labels):ax.imshow(images[i].reshape(28,28),cmap=&quot;gray&quot;) ax.set_title(label.item()) ax.axes.get_xaxis().set_visible(False)ax.axes.get_yaxis().set_visible(False)</code></pre><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/FashionMNIST_dataset.png" srcset="undefined" class=""><h2 id="lenet-5"><a class="markdownIt-Anchor" href="#lenet-5"></a> LeNet-5</h2><p>接下来我们就可以构建一个CNN了。截至2020年人们对CNN的研究已经超过22年，其中诞生了很多经典的网络结构，而这次我们实现的是最早的一个CNN，Yann LeCun的LeNet-5。这里的5表示这个网络有5层，以卷积层-最大池化层-卷积层-最大池化层-全连接层排列，如下图。</p><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/lenet.png" srcset="undefined" class=""><p>图上的每一个方框代表CNN网络的一层，具体结构如下</p><table><thead><tr><th>层名</th><th>输入形状</th><th>输出形状</th><th>核/窗口尺寸</th></tr></thead><tbody><tr><td>conv1</td><td>1*28*28</td><td>6*24*24</td><td>5*5</td></tr><tr><td>pool1</td><td>6*24*24</td><td>16*12*12</td><td>2*2</td></tr><tr><td>conv2</td><td>16*12*12</td><td>16*8*8</td><td>5*5</td></tr><tr><td>pool2</td><td>16*8*8</td><td>16*4*4</td><td>2*2</td></tr><tr><td>linear1</td><td>256</td><td>120</td><td>N/A</td></tr><tr><td>linear2</td><td>120</td><td>84</td><td>N/A</td></tr><tr><td>linear3</td><td>84</td><td>10</td><td>N/A</td></tr></tbody></table><p>注：原始的LeNet设计的输入形状为1*32*32，这里为了适应MNIST数据集减小了CNN的输入和输出的尺寸，但通道数和全连接层输入输出尺寸保持不变。计算卷积层输出形状参照以下公式：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">输</mi><mi mathvariant="normal">出</mi><mi mathvariant="normal">尺</mi><mi mathvariant="normal">寸</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">输</mi><mi mathvariant="normal">入</mi><mi mathvariant="normal">尺</mi><mi mathvariant="normal">寸</mi><mo>−</mo><mi mathvariant="normal">卷</mi><mi mathvariant="normal">积</mi><mi mathvariant="normal">核</mi><mi mathvariant="normal">尺</mi><mi mathvariant="normal">寸</mi><mo>+</mo><mn>2</mn><mo>∗</mo><mi mathvariant="normal">填</mi><mi mathvariant="normal">充</mi><mi mathvariant="normal">尺</mi><mi mathvariant="normal">寸</mi><mo stretchy="false">(</mo><mi>p</mi><mi>a</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">步</mi><mi mathvariant="normal">长</mi><mo stretchy="false">(</mo><mi>S</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">输出尺寸=\frac{输入尺寸-卷积核尺寸+2*填充尺寸(padding)}{步长(Stride)}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">输</span><span class="mord cjk_fallback">出</span><span class="mord cjk_fallback">尺</span><span class="mord cjk_fallback">寸</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord cjk_fallback mtight">步</span><span class="mord cjk_fallback mtight">长</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord cjk_fallback mtight">输</span><span class="mord cjk_fallback mtight">入</span><span class="mord cjk_fallback mtight">尺</span><span class="mord cjk_fallback mtight">寸</span><span class="mbin mtight">−</span><span class="mord cjk_fallback mtight">卷</span><span class="mord cjk_fallback mtight">积</span><span class="mord cjk_fallback mtight">核</span><span class="mord cjk_fallback mtight">尺</span><span class="mord cjk_fallback mtight">寸</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mbin mtight">∗</span><span class="mord cjk_fallback mtight">填</span><span class="mord cjk_fallback mtight">充</span><span class="mord cjk_fallback mtight">尺</span><span class="mord cjk_fallback mtight">寸</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>，再加上输出的通道数可以得到最终的输出形状。例如输入形状为1*28*28，卷积核尺寸为5*5，输出的尺寸就为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mn>28</mn><mo>−</mo><mn>5</mn><mo>+</mo><mn>2</mn><mo>∗</mo><mn>0</mn></mrow><mn>1</mn></mfrac><mo>+</mo><mn>1</mn><mo>=</mo><mn>24</mn></mrow><annotation encoding="application/x-tex">\frac{28-5+2*0}{1}+1=24</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">8</span><span class="mbin mtight">−</span><span class="mord mtight">5</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mbin mtight">∗</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">4</span></span></span></span>，再定义输出6个通道，因此输出形状为6*24*24。</p><p>我们可以看到LeNet的每一层输入和输出大小不断减小，但通道数不断增加。每一层的大小减小表明CNN网络在不断地减少无用的信息，而通道数增加则是为了让网络有更多参数提取图像中的重要特征。在CNN中，每一个通道都代表了原图中的一个特征，通道数越多能够提取到的特征数量就越多，因此一些现代的CNN往往有384，512甚至1024个通道。</p><h2 id="构建网络"><a class="markdownIt-Anchor" href="#构建网络"></a> 构建网络</h2><p>从这里开始，我们遇到的神经网络层数就慢慢变多了。对于这种复杂的网络nn.Sequential就显得力不从心了。因此我们使用一个Python类来定义网络。这个类继承nn.Module类，在<code>__init__</code>里定义网络结构，另外还需要一个<code>forward</code>方法表明正向传播的路径。有了这两个信息pytorch就能自动补全反向传播的路径。下面来看看这个类是如何定义的。</p><pre><code>from torch import nnfrom torch.nn.functional import reluclass LeNet5(nn.Module):def __init__(self):   super(LeNet5, self).__init__()self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)self.pool1 = torch.nn.MaxPool2d(kernel_size=2,stride=2)self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)self.linear1 = torch.nn.Linear(256, 120)   self.linear2 = torch.nn.Linear(120, 84)      self.linear3 = torch.nn.Linear(84, 10)      def forward(self, x):#使用relu函数而不是将激活函数定义在网络结构中x = relu(self.conv1(x))  x = self.pool1(x)x = relu(self.conv2(x))x = self.pool2(x)#将来自池化层的三维输出（通道数，高，宽）扁平化为向量输入进全连接层x = x.view(-1, 256)x = relu(self.linear1(x))x = relu(self.linear2(x))x = self.linear3(x)        return xnet = LeNet5()</code></pre><p>为了确认我们定义的网络结构是否正确，我们需要查看一下网络结构。pytorch有两个非常方便的插件可以让我们查看网络的结构，分别是<a href="https://github.com/sksq96/pytorch-summary" target="_blank" rel="noopener">torchsummary</a>和<a href="https://github.com/szagoruyko/pytorchviz" target="_blank" rel="noopener">pytorchviz</a>。我们使用pip安装这两个插件<code>pip install torchviz torchsummary</code>。torchsummary可以将网络结构，输出尺寸，参数数量等信息用文字和表格的方式清晰地表示出来，首先我们先用这个插件查看一下我们网络的结构。</p><pre><code>from torchsummary import summary#如果使用了带有CUDA的pytorch需要先将网络移动到显存中，否则会有CUDA张量和pytorch张量不兼容的问题net.to(torch.device(&quot;cuda&quot;))#第二个参数为输入形状，对于CNN来说形状通常为(通道数，高，宽)summary(net, (1,28,28))#使用CPU亦可。通常运行在CPU上报错信息会更加详细，如果遇到错误可以切换到CPU查看错误原因net.to(torch.device(&quot;cpu&quot;))summary(net, (1,28,28),device=&quot;cpu&quot;)</code></pre><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/summary.png" srcset="undefined" class=""><p>可以看到整个网络的结构都已经清晰地显示出来了。从此处我们也可以看出全连接层和卷积层参数数量巨大的差异。</p><p>torchviz可以像caffe2一样将计算图画出来，要使用torchviz需要安装<a href="https://www.graphviz.org/download/" target="_blank" rel="noopener">graphviz</a>并加进系统的环境变量中。安装好后可以使用</p><pre><code>#torch.randn会随机生成一个给定形状的张量，这里的形状是（批量大小，通道，高，宽），如果是CUDA版的pytorch依然要将张量移动到显存中x = torch.randn(1,1,28,28).to(torch.device(&quot;cuda&quot;))y= net(x)make_dot(y.mean(),params=dict(net.named_parameters()))</code></pre><p>这个插件会自动生成一张网络的计算图，由于计算图包含了反向传播的部分所以显得比较复杂，在需要时可以参考使用。</p><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/computational_graph.png" srcset="undefined" class=""><p>确认网络结构无误后，我们就可以训练了。向原来的初始化函数加一个对<code>nn.Conv2d</code>层的初始化，同样使用交叉熵损失函数和Adam优化算法。</p><pre><code>def init_weights(m):if type(m) == nn.Linear:nn.init.normal_(m.weight)m.bias.data.fill_(0.01)if type(m) == nn.Conv2d:nn.init.normal_(m.weight)m.bias.data.fill_(0.01)</code></pre><p>net.apply(init_weights)<br />criterion = torch.nn.CrossEntropyLoss()</p><pre><code>net.apply(init_weights)criterion = torch.nn.CrossEntropyLoss()optimizer = torch.optim.Adam(net.parameters(),lr=0.01)</code></pre><p>训练时注意CNN不需要将图像变成向量传进网络，卷积层需要直接处理原图。</p><pre><code>#如果之前将网络移动到显存上查看结构，使用CPU训练时需要将网络移动回CPUnet.to(torch.device(&quot;cpu&quot;))for epoch in range(5):loss = 0for _, data in enumerate(train_loader):features, labels = dataoptimizer.zero_grad()outputs = net(features)loss = criterion(outputs,labels)loss.backward()optimizer.step()#每运行完一代就显示训练效果print(&quot;epoch {}, loss {}&quot;.format(epoch+1,loss.data.item()))</code></pre><p>由于CNN较之前的网络复杂，如果能使用CUDA加速的话可以使用如下训练代码。</p><pre><code>#将网络移动到显存上net.to(torch.device(&quot;cuda&quot;))#使用显存上的网络参数定义优化算法optimizer = torch.optim.Adam(net.parameters(),lr=0.01)for epoch in range(5):loss = 0for _, data in enumerate(train_loader):features, labels = data#将特征和标签移动到显存上features, labels = features.cuda(), labels.cuda()optimizer.zero_grad()outputs = net(features)loss = criterion(outputs,labels)loss.backward()optimizer.step()#每运行完一代就显示训练效果print(&quot;epoch {}, loss {}&quot;.format(epoch+1,loss.data.item()))</code></pre><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/normal_loss.png" srcset="undefined" class=""><p>奇怪的是在迭代5代后，损失依旧保持在1左右，而我们查看准确度则更是惨不忍睹</p><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/normal_accuracy.png" srcset="undefined" class=""><p>作为对比，我们看看上一节编写的手写数字识别网络在使用FashionMNIST的准确率</p><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/fc_accuracy.png" srcset="undefined" class=""><p>我们花费这么多精力设计出的比多层感知机复杂得多的卷积神经网络难道根本就一无是处？答案显然是否定的，我们的CNN训练结果如此糟糕和很多方面都有联系，而其中一个方面就是我们使用的初始化函数。到目前为止，我们都在沿用最简单的使用标准正态分布生成随机数的方法。这种方法的问题是容易生成过大或者过小的初始化参数。尽管正态分布生成的随机数落在一个标准差之间的概率最大，但落在两端的概率在动辄上万，甚至上亿个参数的神经网络里是无法被忽视的。那么过大或过小的参数会带来什么问题呢？这会对神经网络反向传播的性能有很大影响。简单地说，这会造成梯度爆炸和梯度消失两个不同的问题。</p><h2 id="一点数学"><a class="markdownIt-Anchor" href="#一点数学"></a> 一点数学</h2><p><em>以下内容包含一点高等数学，如对数学无感可跳过看结论</em></p><p>还记得我们之前提到过反向传播使用微分修正参数吗？大致来说反向传播是一个求偏导的过程。假设我们有一个两层，每层只有一个神经元的网络，每一层上有一个激活函数，也就是网络结构如下</p><p><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="524px" height="212px" viewBox="73 115 427 173" preserveAspectRatio="xMidYMid meet" ><rect id="svgEditorBackground" x="0" y="0" width="1050" height="570" style="fill:none; stroke: none;"/><circle id="e1_circle" cx="318.77227783203125" cy="158.90536499023438" style="fill:none;stroke:black;stroke-width:1px;" r="53.8144961883" transform="matrix(0.419978 0 0 0.419978 104.372 123.513)"/><circle id="e14_circle" cx="97.80815124511719" cy="159.38104248046875" style="fill:none;stroke:black;stroke-width:1px;" r="53.8144961883" transform="matrix(0.419978 0 0 0.419978 104.372 123.513)"/><circle id="e2_circle" cx="543.5452270507812" cy="155.09463500976562" style="fill:none;stroke:black;stroke-width:1px;" r="53.8144961883" transform="matrix(0.419978 0 0 0.419978 104.372 123.513)"/><path d="M168,190h48" style="fill:none;stroke:black;stroke-width:1px;" id="e5_pathH"/><path d="M262,190h48" style="fill:none;stroke:black;stroke-width:1px;" id="e2_pathH"/><text style="fill:black;font-family:Arial;font-size:20px;" x="133" y="187" id="e6_texte"></text><text style="fill:black;font-family:Arial;font-size:20px;" x="94.95985412597656" y="234.56033325195312" id="e7_texte" transform="matrix(0.912421 0 0 0.912421 53.4807 -17.5701)">x</text><text style="fill:black;font-family:Arial;font-size:20px;" x="177" y="182" id="e8_texte">w1</text><text style="fill:black;font-family:Arial;font-size:20px;" x="232" y="196" id="e9_texte">f1</text><text style="fill:black;font-family:Arial;font-size:20px;" x="269" y="184" id="e10_texte">w2</text><text style="fill:black;font-family:Arial;font-size:20px;" x="326" y="195" id="e11_texte">f2</text><path d="M356,190h48" style="fill:none;stroke:black;stroke-width:1px;" id="e1_pathH"/><text style="fill:black;font-family:Arial;font-size:20px;" x="428" y="193" id="e14_texte"></text><text style="fill:black;font-family:Arial;font-size:20px;" x="410" y="188" id="e15_texte"></text><circle id="e3_circle" cx="765.462890625" cy="155.57034301757812" style="fill:none;stroke:black;stroke-width:1px;" r="53.8144961883" transform="matrix(0.419978 0 0 0.419978 104.372 123.513)"/><text style="fill:black;font-family:Arial;font-size:20px;" x="176" y="253" id="e16_texte" transform="matrix(1 0 0 1 244 -59)">y</text></svg></p><p>从图中我们可以看出这个网络的正向传播可以用如下等式表示</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>f</mi><mn>2</mn></msub><mo stretchy="false">(</mo><msub><mi>w</mi><mn>2</mn></msub><mo>∗</mo><mo stretchy="false">(</mo><msub><mi>f</mi><mn>1</mn></msub><mo stretchy="false">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo>∗</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y = f_2(w_2*(f_1(w_1*x)))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p>而反向传播则是用误差对其中一个权重求偏导来对权重进行更新，例如对<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>求偏导得</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>w</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>f</mi><mn>2</mn></msub></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi>f</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>f</mi><mn>1</mn></msub></mrow></mfrac><msub><mi>w</mi><mn>2</mn></msub><mo>⋅</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi>f</mi><mn>1</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>1</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\Delta w = \frac{\partial loss}{\partial w_1} = \frac{\partial loss}{\partial f_2} \cdot \frac{\partial f_2}{\partial f_1}w_2 \cdot \frac{\partial f_1}{\partial w_1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.20744em;vertical-align:-0.8360000000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.25188em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.25188em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714399999999998em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.20744em;vertical-align:-0.8360000000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714399999999998em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>然后再将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">\Delta w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span></span></span></span>加到原权重上</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><mo>+</mo><mi mathvariant="normal">Δ</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">w_1 = w_1 + \Delta w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span></span></span></span></span></p><p>在这个过程中权重<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>需要和激活函数的导数相乘。如果激活函数是sigmoid函数，而sigmoid函数的导数如下图</p><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/sigmoid_D.png" srcset="undefined" class=""><p>由于sigmoid的导数值域为(0,0.25]，当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>初始化的值过小，在经过反向传播后<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">\Delta w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span></span></span></span>就会趋近于0，导致<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>得不到更新。同理当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>初始化值过大导致导数乘<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的值超过1，反向传播后得到的梯度会越来越大直至超过计算机的表示范围。随着网络层数增加，在反向传播时需要相乘的权重也会变多。在其中如果有多个权重初始化值不在理想范围就会导致最后得到的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">\Delta w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span></span></span></span>值过大或过小，使神经网络权重更新不稳定以至于无法收敛。需要注意的是梯度爆炸和梯度消失的原因有很多方面，例如从这个反向传播等式中我们也可以看出如果激活函数的导数过小梯度也会消失，这就是之前讲到的sigmoid会导致神经网络学习缓慢的原因。</p><p><strong>结论：使用正态分布初始化网络会产生过大或过小的权重参数，当网络变深时这些参数会使网络权重更新不稳定以至于无法收敛。</strong></p><p>因此，人们提出了两种新的初始化方法：Xavier初始化和He初始化。在这里我们不会深入讨论这两个初始化的细节，只需要知道Xavier初始化是针对sigmoid和tanh激活函数开发，而He初始化是针对ReLU激活函数对Xavier初始化提出的改善就可以了。</p><p>那么，我们修改一下权重的初始化函数，然后重新训练CNN看看结果如何。由于我们使用的是ReLU激活函数，我们选择He初始化函数进行初始化</p><pre><code>def init_weights(m):if type(m) == nn.Linear:#在pytorch中He初始化被称作kaiming_uniform_或kaiming_normal_，这是因为He初始化论文作者名为何恺明博士#uniform和normal指的是使用均匀分布还是正态分布版本的He初始化，在这里我们选择均匀分布nn.init.kaiming_normal_(m.weight)m.bias.data.fill_(0.01)if type(m) == nn.Conv2d:nn.init.kaiming_normal_(m.weight)m.bias.data.fill_(0.01)net.apply(init_weights)</code></pre><p>然后我们再来训练一次看看结果如何</p><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/he_loss.png" srcset="undefined" class=""><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/he_accuracy.png" srcset="undefined" class=""><p>可以看到效果立竿见影，识别的准确率已经超过了全连接网络，达到了86.27%，这说明使用CNN确实会对图像识别有很大改善。</p><h1 id="使用caffe2构建网络"><a class="markdownIt-Anchor" href="#使用caffe2构建网络"></a> 使用caffe2构建网络</h1><p>由于caffe2官方没有提供FashionMNIST数据集，我们需要自己制作一个可以用在caffe2的FashionMNIST数据集。由于MNIST数据集和FashionMNIST数据集完全兼容，我们可以使用caffe2提供的一个小工具<code>make_mnist_db</code>制作数据集。首先我们需要从FashionMNIST的<a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank" rel="noopener">github</a>上下载数据集的原始文件。分别为<em>train-images-idx3-ubyte.gz</em>，<em>train-labels-idx1-ubyte.gz</em>，<em>t10k-images-idx3-ubyte.gz</em>和<em>t10k-labels-idx1-ubyte.gz</em>。下载解压后调用<code>make_mnist_db</code>生成LevelDB或LMDB格式的数据集。<code>make_mnist_db</code>位于pytorch编译目录的build\bin文件夹中。在Windows下如果遇到找不到nvtoolsext64_1.dll的问题将anaconda3\pkgs\cudatoolkit-*\Library\bin加入系统的PATH环境变量再重试一次。</p><pre><code>#--db参数可以选择lmdb或leveldb --image_file和--lavel_file分别是图像和标签文件位置#生成训练集make_mnist_db --channel_first true --db lmdb --image_file path/to/train-images-idx3-ubyte --label_file path/to/train-labels-idx1-ubyte --output_file output/fashionmnist-train-nchw-lmdb#生成测试集make_mnist_db --channel_first true --db lmdb --image_file path/to/t10k-images-idx3-ubyte --label_file path/to/t10k-labels-idx1-ubyte --output_file output/fashionmnist-test-nchw-lmdb</code></pre><p>生成后我们就可以用同样的加载代码载入数据集了</p><pre><code>from caffe2.python import brew, core, model_helper, optimizer, workspace, net_drawertrain_model = model_helper.ModelHelper(&quot;train_model&quot;,arg_scope={&quot;order&quot;:&quot;NCHW&quot;})#注意修改文件位置，如果上一步使用LevelDB格式生成数据集这里的db_type也要改成对应的leveldbfeatures_uint8, labels = train_model.TensorProtosDBInput([],[&quot;features_uint8&quot;,&quot;labels&quot;],batch_size=50,db=&quot;path/to/fashionmnist-train-nchw-lmdb&quot;,db_type=&quot;lmdb&quot;)features = train_model.Cast(features_uint8, &quot;features&quot;, to=core.DataType.FLOAT)features = train_model.Scale(features,features,scale=float(1/256))features = train_model.StopGradient(features,features)</code></pre><p>接下来我们就要构建一个LeNet-5网络了</p><pre><code>#weight_init定义使用的初始化函数，我们依然使用He初始化初始化权重#由于何恺明是在微软亚洲研究院(MSRA)研究出的He初始化，caffe2中He初始化被称作MSRAFillconv1 = brew.conv(train_model, features, &quot;conv1&quot;,dim_in=1,dim_out=6,weight_init=(&quot;MSRAFill&quot;,{}),kernel=5)relu1 = brew.relu(train_model, conv1, &quot;relu1&quot;)pool1 = brew.max_pool(train_model, relu1, &quot;pool1&quot;,kernel=2,stride=2)conv2 = brew.conv(train_model, pool1, &quot;conv2&quot;, dim_in=6,dim_out=16, weight_init=(&quot;MSRAFill&quot;,{}),kernel=5)relu2 = brew.relu(train_model,conv2,&quot;relu2&quot;)pool2 = brew.max_pool(train_model,relu2,&quot;pool2&quot;,kernel=2,stride=2)fc1 = brew.fc(train_model,pool2,&quot;fc1&quot;,dim_in=16*4*4,dim_out=120,weight_init=(&quot;MSRAFill&quot;,{}))relu3 = brew.relu(train_model,fc1,&quot;relu3&quot;)fc2 = brew.fc(train_model,relu3,&quot;fc2&quot;,dim_in=120,dim_out=84,weight_init=(&quot;MSRAFill&quot;,{}))relu4 = brew.relu(train_model,fc2,&quot;relu4&quot;)fc3 = brew.fc(train_model,relu4,&quot;fc3&quot;,dim_in=84,dim_out=10,weight_init=(&quot;MSRAFill&quot;,{}))softmax = brew.softmax(train_model,fc3,&quot;softmax&quot;)</code></pre><p>同样还有交叉熵函数</p><pre><code>crossEntropy = train_model.LabelCrossEntropy([softmax,labels],&quot;crossEntropy&quot;)loss = train_model.AveragedLoss(crossEntropy, &quot;loss&quot;)</code></pre><p>确认计算图</p><pre><code>from IPython import displaygraph = net_drawer.GetPydotGraph(train_model.Proto().op,&quot;train&quot;,rankdir=&quot;LR&quot;)display.Image(graph.create_png(),width=800)</code></pre><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/lenet_graph.png" srcset="undefined" class=""><p>下面使用同样的Adam优化算法</p><pre><code>train_model.AddGradientOperators([loss])optimizer.build_adam(    train_model,    base_learning_rate=0.001,    policy=&quot;step&quot;,    stepsize=1,    gamma=0.999,)</code></pre><p>我们将整个数据集迭代5次。由于每个小批量大小是50，FashionMNIST的训练集大小是50000，我们需要迭代5000次。</p><pre><code>workspace.RunNetOnce(train_model.param_init_net)workspace.CreateNet(train_model.net)total_iters = 5000loss = [0 for i in range(5000)]for i in range(total_iters):workspace.RunNet(train_model.net.Proto().name)loss[i] = workspace.FetchBlob('loss')loss</code></pre><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/caffe2_loss.png" srcset="undefined" class=""><img src="/2020/04/20/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-CNN%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E7%BD%91%E7%BB%9C/caffe2_plot.png" srcset="undefined" class=""><p>最后进行测试，注意要将init_params设成False，防止测试网络重新初始化参数。</p><pre><code>test_model = model_helper.ModelHelper(&quot;test_model&quot;,arg_scope={&quot;order&quot;:&quot;NCHW&quot;},init_params=False) features_test_uint8, labels_test = test_model.TensorProtosDBInput([],[&quot;features_test_uint8&quot;,&quot;labels_test&quot;],batch_size=200,db=&quot;fashionmnist-test-nchw-lmdb&quot;,db_type=&quot;lmdb&quot;)features_test = test_model.Cast(features_test_uint8, &quot;features_test&quot;, to=core.DataType.FLOAT)features_test = test_model.Scale(features_test,features_test,scale=float(1/256))features_test = test_model.StopGradient(features_test,features_test)conv1 = brew.conv(test_model, features_test, &quot;conv1&quot;,dim_in=1,dim_out=6,kernel=5)relu1 = brew.relu(test_model, conv1, &quot;relu1&quot;)pool1 = brew.max_pool(test_model, relu1, &quot;pool1&quot;,kernel=2,stride=2)conv2 = brew.conv(test_model, pool1, &quot;conv2&quot;, dim_in=6,dim_out=16,kernel=5)relu2 = brew.relu(test_model,conv2,&quot;relu2&quot;)pool2 = brew.max_pool(test_model,relu2,&quot;pool2&quot;,kernel=2,stride=2)fc1 = brew.fc(test_model,pool2,&quot;fc1&quot;,dim_in=16*4*4,dim_out=120)relu3 = brew.relu(test_model,fc1,&quot;relu3&quot;)fc2 = brew.fc(test_model,relu3,&quot;fc2&quot;,dim_in=120,dim_out=84)relu4 = brew.relu(test_model,fc2,&quot;relu4&quot;)fc3 = brew.fc(test_model,relu4,&quot;fc3&quot;,dim_in=84,dim_out=10)softmax = brew.softmax(test_model,fc3,&quot;softmax&quot;)accuracy = brew.accuracy(test_model, [softmax,labels_test],&quot;accuracy&quot;)</code></pre><p>查看测试结果</p><pre><code>import numpy as npworkspace.RunNetOnce(test_model.param_init_net)workspace.CreateNet(test_model.net)total_iters = 50accuracy = np.zeros(50)for i in range(total_iters):workspace.RunNet(test_model.net)accuracy[i] = workspace.FetchBlob(&quot;accuracy&quot;)plt.plot(accuracy)print(&quot;test accuracy:{}&quot;.format(accuracy.mean()))</code></pre><p>至此一个简单的CNN网络就搭建完成了，接下来几节我们将认识更多更加复杂的CNN结构，并使用CINIC-10进行训练。</p>]]></content>
    
    
    <categories>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>caffe2</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch&amp;caffe2 深度学习的魔法 手写数字识别网络</title>
    <link href="undefined2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/"/>
    <url>2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<p>本节我们将构建第一个有实际用处的网络：手写数字识别网络。这个网络使用了非常经典的MNIST数据集(Modified National Institute of Standards and Technology 经修改的美国国家标准与技术研究所数据集)进行训练（<a href="https://www.nist.gov/system/files/documents/srd/nistsd19.pdf" target="_blank" rel="noopener">原始数据集</a>介绍在此文件中描述，MNIST包含的是Special Database 1和Special Database 3，Special Database 1中包含的是高中生的手写数字，Special Database 3中包含的是美国人口调查局职员的手写数字）。这个数据集中包含了60000个尺寸为28*28的手写数字，由于它尺寸统一且适中，并且手写数字大部分都特征明显，因此很适合作为神经网络的第一个例子展示。</p><h1 id="神经网络数据集"><a class="markdownIt-Anchor" href="#神经网络数据集"></a> 神经网络数据集</h1><p>在上一个例子中我们使用线性函数自己生成了数据集，但大部分情况下数据集准备并没有这么简单，通常需要耗费大量时间和人力为数据添加标签然后给神经网络训练。好在现在有很多开源数据集供我们使用，因此在学习时我们通常可以忽略这一步，但如果要实际训练一个自己的网络，这通常是最困难的一步之一。</p><p>不论是使用别人预先准备好的数据集还是自己收集的数据集，我们都有必要在让神经网络学习前先查看数据集的内容与结构，并在必要时对数据进行一些预处理。一个好的数据集对于神经网络的训练效果至关重要，想象一下如果你在学英语时书上告诉你cat的意思是狗，那么你再聪明也无法领会到cat的真正意思是猫。当然，作为一个久经考验的数据集，MNIST不需要我们操心数据的正确性，但我们仍需要进行一些必要的预处理。</p><p>从这一节开始，我们用到的数据集都分为训练集和测试集。在训练线性回归网络时我们并没有特意分出测试集，由于线性回归网络十分简单，我们可以直接检查参数检验训练成果。而识别MNIST的网络则要复杂得多，参数的意义也并不明确，因此我们需要专门准备一个测试集测试网络的训练成果。要注意测试集<strong>绝对不能</strong>在训练时使用，因为神经网络参数非常多，我们并不清楚训练时的优异表现是否是因为神经网络用这些参数“记忆”了训练集的每一个数字和标签的关系，还是真正的学习到了数字间形状的差异，因此测试集必须是一个独立的，神经网络从未见过的数据，这样我们才能准确地判断神经网络的表现。</p><h1 id="使用pytorch构建网络"><a class="markdownIt-Anchor" href="#使用pytorch构建网络"></a> 使用pytorch构建网络</h1><h2 id="下载mnist数据集"><a class="markdownIt-Anchor" href="#下载mnist数据集"></a> 下载MNIST数据集</h2><p>由于MNIST数据集十分常用，pytorch专门为它构建了一个工具类完成下载和导入过程，我们只需要调用这个类便可自动下载MNIST数据集。</p><p>打开一个新的jupyter记事本，导入torch和torchvision的datasets两个包，torchvision是pytorch专门用于处理计算机视觉使用的包，即让计算机能够像人类一样“看懂”图片。datasets里有很多预置的常用数据集，我们可以使用dir看一看它包含的数据集。</p><p>虽然我们这次要用到的是MNIST数据集，但查看datasets中包含的数据集会发现有很多数据集名字中包含MNIST：QMNIST，EMNIST，KMNIST和FashionMNIST。这几个数据集的共同之处是它们提供的图片都是28*28的位图，但其中包含的内容与MNIST有些不同。由于MNIST现在识别率非常高，很难看出不同的网络间有多大差距，因此人们使用同样的数据格式扩充了MNIST，有的包含更多的手写数字（QMNIST和EMNIST），而有的则直接换了图像的内容（FashionMNIST包含的是衣服图片和对应名称，而KMNIST是古日语文字和对应的假名分类）。这些数据集显著拉开不同网络结构的性能差异，因此我们后面的网络也会换用这些数据集体现差异。<br />首先我们先导入训练集和测试集。</p><pre><code>from torchvision import transforms#datasets.MNIST(加载路径，是否使用训练集（设为False导入测试集），#文件不存在下载，数据集预处理函数）train_loader = torch.utils.data.DataLoader(    datasets.MNIST('./MNIST', train=True, download=True,transform=transforms.ToTensor()),    batch_size=50, shuffle=True)test_loader =  torch.utils.data.DataLoader(    datasets.MNIST('./MNIST', train=False, download=True,transform=transforms.ToTensor()),    batch_size=50, shuffle=True)</code></pre><p>这里我们第一次遇到数据集预处理的概念。所谓预处理就是对数据集的内容进行一些必要的操作以让神经网络能够正确识别数据，进而提高神经网络的训练效率和性能。这里我们的操作非常简单，只是将原本的位图格式的图片转换为pytorch张量。torchvision提供的transforms有很多常用的预处理函数，我们在后面会经常遇到。</p><p>将数据集导入Python之后，我们就可以查看这个数据集中的图片是什么样的了。由于DataLoader实现了*<strong>iter</strong>*方法，在这里我们使用python提供的iter和next函数获取train_loader的第一个小批量数据。</p><pre><code>images, labels = next(iter(train_loader))images.size(),labels.size()</code></pre><p>我们可以看到第一个小批量样本的大小是50，也就是我们设置的batch_size大小，后面的1,28,28则表示每张图尺寸是28*28，有一个通道<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>。而标签大小也为50，也就是每一张图都有一个标签。我们使用matplotlib来查看其中的10张图像和对应的标签。</p><pre><code>import matplotlib.pyplot as plt%matplotlib inlinefigs,axs = plt.subplots(1,10, figsize=(20, 20)) #matplotlib的subplots可以让多张图片在同一行显示。这里的1,10表示生成的显示区域是1*10的for ax,i,label in zip(axs,range(0,10),labels):ax.imshow(images[i].reshape(28,28),cmap=&quot;gray&quot;) #将图片转成28*28的张量ax.set_title(label.item()) ax.axes.get_xaxis().set_visible(False)ax.axes.get_yaxis().set_visible(False)</code></pre><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/mnist_first10.png" srcset="undefined" class=""><p>由于开启了shuffle选项，每个人的读取结果都会不同，但是我们可以清楚的看到不同的数字对应不同的标签。作为人，我们自然能认识所有的数字，接下来我们就要让计算机学习不同数字的写法和对应的标签来认识这些数字。</p><h2 id="softmax回归"><a class="markdownIt-Anchor" href="#softmax回归"></a> softmax回归</h2><p>神经网络识别数字相当于将不同的数字图像分类到对应的数字下。由于不同的类别是一个离散的数值，像生成一个连续函数的线性回归就不太适用了。因此我们需要使用更加适合离散值分类的模型，例如softmax回归。softmax回归通过以e为底的指数函数（exp函数）将神经网络的输出正则化为一个合法的概率分布。由于exp的值域为(0,∞)，exp函数可以保证计算时所有的输出均为正数。它的公式非常简单，为</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">p_i = \frac{exp(x_i)}{\sum_{j=1}^{n} exp(x_j)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.55711em;vertical-align:-1.1301100000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.305708em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1301100000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>。softmax回归后所有类别的可能性就组成了一个概率分布，这样我们就能很方便的衡量神经网络的真实输出了。可以点击<a href="https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d" target="_blank" rel="noopener">这里</a>查看关于softmax的详细解释。</p><h2 id="构建网络"><a class="markdownIt-Anchor" href="#构建网络"></a> 构建网络</h2><p>现在已经有很多高级的网络结构来辨识这些手写数字，但是我们还是从最简单的全连接网络开始构建。这种网络也被称为多层感知机，我们使用的多层感知机结构如下图所示。</p><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/mnist_net.png" srcset="undefined" class=""><p>从图上可以看到每一个神经元之间都有连接，这也是为什么这种网络被称作全连接网络。正如上一节介绍，最左边一层是输入层， 最右边一层是输出层，而中间则是隐藏层。但稍加观察即可发现，这种网络只是在线性变换后将移动了张量，也就是进行了一次仿射变换，从更高维上看这只是一次的线性变换（这也是为什么有些框架将全连接层称为仿射层(Affine Layer)。）<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>仿射变换的叠加等价于一个仿射变换，因此不管有多少个隐藏层这个网络仍等价于一层。解决方法很简单，也就是在我们的网络中引入非线性函数，也被称作激活函数(Activation Function)。</p><p>为隐藏层激活函数使隐藏层不单纯是进行仿射变换，也就不会有仿射变换叠加的问题。在神经网络中有四类常见的激活函数，分别为sigmoid函数，ReLU函数和tanh函数。而ReLU又有很多种不同的变种解决了这个函数存在的一些问题。下面我们来简单了解一下这三个函数</p><h3 id="sigmoid函数"><a class="markdownIt-Anchor" href="#sigmoid函数"></a> sigmoid函数</h3><p>sigmoid函数，或者叫logistic sigmoid函数是最古老的激活函数，值域为[0,1]，它的函数图像如下</p><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/logistic_sigmoid.png" srcset="undefined" class=""><p>这个函数受神经科学启发，特点是对中央的信号反应大，而两端的信号反应小，与生物神经元较为相似。然而人工神经网络的工作方式和自然神经网络有很大不同，人工神经网络依赖梯度学习，而sigmoid函数的两端梯度很小甚至消失。这种情况也被称作激活函数软饱和，sigmoid因此是一个饱和激活函数，即这个函数在x趋向无穷时导数趋近于0。这种情况导致神经网络学习缓慢或者无法学习，因此人们便设计出了ReLU替代。</p><h3 id="relu函数"><a class="markdownIt-Anchor" href="#relu函数"></a> ReLU函数</h3><p>ReLU全称是修正线性单元(Rectified Linear Unit)，从名称可以得知它有一部分是线性函数，而它的非线性则体现在x&lt;0时函数值取0，当x&gt;0时函数值为x，如下图</p><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/ReLU.png" srcset="undefined" class=""><p>这个函数构造简单，而且在正数部分趋向正无穷（永远不饱和），并且负数部分恒等于0（负数部分硬饱和），解决了梯度消失的问题，因此是现在大部分网络的首选激活函数。但忽略负数部分会导致ReLU有一定几率永远都不被激活，因此人们还提出了其他一些负数部分不硬饱和的函数使ReLU不会在负数部分因为饱和不能正常激活。</p><h3 id="tanh函数"><a class="markdownIt-Anchor" href="#tanh函数"></a> tanh函数</h3><p>tanh函数和sigmoid图像类似，但是值域为[-1,1]，它同样是一个饱和激活函数，图像如下</p><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/tanh.png" srcset="undefined" class=""><p>sigmoid函数和tanh函数尽管由于饱和问题不常用到，但是它们能够限制值域的范围，因此在用于语音处理的循环神经网络和递归神经网络以及它们的变体中有很大用途。</p><p>在加上激活函数后，我们的多层感知机就可以准备学习了，首先我们先构造一个简单的多层感知机。</p><pre><code>from torch import nnnet = nn.Sequential(nn.Linear(28*28,256), #输入28*28=784个，即每个像素对应一个输入层的神经元，隐藏层输出256个nn.ReLU(), #使用ReLU作为激活函数nn.Linear(256,10) #输出层接受来自隐藏层的256个数据，输出神经元为10个，对应10个数字)</code></pre><p>我们使用和线性回归网络一样的初始化函数初始化权重。</p><pre><code>def init_weights(m):if type(m) == nn.Linear:nn.init.normal_(m.weight)m.bias.data.fill_(0.01)net.apply(init_weights)</code></pre><p>在这个网络中，我们使用交叉熵损失函数。这个函数衡量一个事件的发生概率和对应的信息量。一个事件发生概率越小，信息量越大，而熵代表了对所有事件发生的信息量的期望值，熵期望值越大则代表结果越不确定。交叉熵则衡量了两个不同的概率分布间的差距有多大，如果交叉熵函数越小，则两个概率分布越接近。由于我们有一个真实概率分布（即已经加了标签的训练集数据），交叉熵函数只需要衡量训练后的softmax产生的概率分布和真实概率分布间差距就可以知道我们的训练效果。因此交叉熵函数在单分类问题，也就是一个输入只对应一个分类的问题中非常常用。pytorch的交叉熵函数还包含了softmax回归器，所以我们不需要在网络结构中自己加入softmax回归。而梯度下降算法则使用更加常用的Adam优化算法。</p><pre><code>criterion = torch.nn.CrossEntropyLoss()optimizer = torch.optim.Adam(net.parameters(),lr=0.01)</code></pre><p>接下来就可以开始训练了，简洁起见部分重复的注释将不再写在代码中</p><pre><code>for epoch in range(5):loss = 0for _, data in enumerate(train_loader):features, labels = data#将图片变成一维的向量以便送入网络中features = features.view(-1,28*28)optimizer.zero_grad()outputs = net(features)loss = criterion(outputs,labels)loss.backward()optimizer.step()#每运行完一代就显示训练效果print(&quot;epoch {}, loss {}&quot;.format(epoch+1,loss.data.item()))</code></pre><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/result.png" srcset="undefined" class=""><p>可以看到得到的损失非常低，但损失只能体现模型在训练集上的效果，为了衡量这个网络能不能在未知的数据上正常识别数字，我们需要使用测试集。</p><pre><code>correct = 0for features, labels in test_loader:features = features.view(-1,28*28)outputs = net(features)#预测的结果output.data为一个行向量，包含网络对每个图像预测的可信度，数字越大表示网络认为这张图像越有可能是某个数字#torch.max可以获取这个向量中最大值并返回对应的索引_, predicted = torch.max(outputs.data,1)correct += (predicted == labels).sum()print(&quot;accuracy {}%&quot;.format(100*(correct.item()/10000)))</code></pre><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/accuracy.png" srcset="undefined" class=""><p>可以看到我们这个简单的网络的准确度已经达到了95.55%，至此我们的手写数字识别网络就全部完成了，如果感兴趣的话可以调整隐藏层数量和尺寸或者使用上节的SGD算法替代Adam看看训练结果有什么变化。</p><h1 id="使用caffe2构建网络"><a class="markdownIt-Anchor" href="#使用caffe2构建网络"></a> 使用caffe2构建网络</h1><p>在caffe2中构建手写数字识别网络要困难一些，首先我们需要自己导入适用于caffe2的MNIST数据集。caffe2官方已经提供了一个制作好的caffe2的MNIST数据集，可以点这里<a href="http://download.caffe2.ai/databases/mnist-lmdb.zip" target="_blank" rel="noopener">下载</a>，本例改编自<a href="https://caffe2.ai/docs/tutorial-MNIST.html" target="_blank" rel="noopener">官网教程</a>。</p><p>caffe2的数据集通常使用lmdb或者leveldb存储，这是一种高效的嵌入式数据库。下载好后将数据集放在jupyter的根目录下，然后使用ModelHelper创建模型并导入数据。这里为了演示方便没有另外将网络定义写在函数中。实际使用时应该像官方说明中一样将不同功能的层定义在不同的函数中调用。</p><pre><code>from caffe2.python import brew, core, model_helper, optimizer, workspace, net_drawertrain_model = model_helper.ModelHelper(&quot;train_model&quot;,arg_scope={&quot;order&quot;:&quot;NCHW&quot;}) #arg_scope是一个语法糖，在定义网络时arg_scope中的参数会自动传入层的定义中#这里的order是数据集中数据的顺序，即小批量中数据数量，通道，高和宽的顺序#TensorProtosDBInput操作符从指定的db位置读取数据库，db_type对应存储的lmdb格式。第一个参数可以传入一些数据库的reader，在这里我们不需要，而第二个参数代表这个操作符输出的变量列表features_uint8, labels = train_model.TensorProtosDBInput([],[&quot;features_uint8&quot;,&quot;labels&quot;],batch_size=50,db=&quot;mnist-lmdb/mnist-train-nchw-lmdb&quot;,db_type=&quot;lmdb&quot;)# 原始的MNIST数据是使用无符号8位整数(0~255)存储的，我们需要转成浮点数供神经网络学习features = train_model.Cast(features_uint8, &quot;features&quot;, to=core.DataType.FLOAT)#将数值范围从0~255转换为0~1features = train_model.Scale(features,features,scale=float(1/256))#无需反向传播features = train_model.StopGradient(features,features)</code></pre><p>在读取了数据库后，我们就可以开始构建网络的计算部分了。</p><pre><code>#输入层和隐藏层fc1 = brew.fc(train_model,features,&quot;fc1&quot;,dim_in = 28*28, dim_out = 256)#增加激活函数relu = brew.relu(train_model, fc1, &quot;relu&quot;)pred = brew.fc(train_model, relu, &quot;pred&quot;,256,10)#caffe2的交叉熵和softmax是分开的，所以我们需要在模型里加入softmax回归softmax = brew.softmax(train_model,relu,&quot;softmax&quot;)</code></pre><p>接下来增加交叉熵函数</p><pre><code>crossEntropy = train_model.LabelCrossEntropy([softmax,labels],&quot;crossEntropy&quot;)#由于caffe2的交叉熵操作符输出的是每一个预测值对应的损失，我们使用AveragedLoss操作符取平均值loss = train_model.AveragedLoss(crossEntropy, &quot;loss&quot;)</code></pre><p>同样我们可以看一看到目前为止的运算图</p><pre><code>from IPython import displaygraph = net_drawer.GetPydotGraph(train_model.Proto().op,&quot;train&quot;,rankdir=&quot;LR&quot;)display.Image(graph.create_png(),width=800)</code></pre><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/caffe2_graph.png" srcset="undefined" class=""><p>在图上我们可以看到读取到的图像经过了多层感知机的几个运算符，并在交叉熵运算符处汇合。</p><p>下面定义训练过程，我们同样使用Adam优化算法。</p><pre><code>train_model.AddGradientOperators([loss])optimizer.build_adam(    train_model,    base_learning_rate=0.001,    policy=&quot;step&quot;,    stepsize=1,    gamma=0.999,)</code></pre><p>最后进行训练。需要注意的是caffe2和pytorch不同，每一次迭代指的是基于一个小批量训练。由于我们每个小批量大小是50，10000次相当于对整个MNIST的训练集迭代10次（MNIST训练集数量为50000）。</p><pre><code>workspace.RunNetOnce(train_model.param_init_net)workspace.CreateNet(train_model.net)total_iters = 10000loss = [0 for i in range(10000)]for i in range(total_iters):workspace.RunNet(train_model.net.Proto().name)loss[i] = workspace.FetchBlob('loss')loss</code></pre><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/caffe2_final.png" srcset="undefined" class=""><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/caffe2_plot.png" srcset="undefined" class=""><p>最后我们对这个网络进行测试。测试方法是再构建一个只包含正向传播的一个测试网络，也就是将训练网络的反向传播部分去除。由于我们需要使用训练网络中的参数，测试网络就不需要再自己初始化参数了，因此ModelHelper的init_params参数设为False。</p><pre><code>test_model = model_helper.ModelHelper(&quot;test_model&quot;,arg_scope={&quot;order&quot;:&quot;NCHW&quot;},init_params=False) features_test_uint8, labels_test = test_model.TensorProtosDBInput([],[&quot;features_test_uint8&quot;,&quot;labels_test&quot;],batch_size=200,db=&quot;mnist-lmdb/mnist-test-nchw-lmdb&quot;,db_type=&quot;lmdb&quot;)features_test = test_model.Cast(features_test_uint8, &quot;features_test&quot;, to=core.DataType.FLOAT)features_test = test_model.Scale(features_test,features_test,scale=float(1/256))features_test = test_model.StopGradient(features_test,features_test)fc1 = brew.fc(test_model,features_test,&quot;fc1&quot;,dim_in = 28*28, dim_out = 256)relu = brew.relu(test_model, fc1, &quot;relu&quot;)pred = brew.fc(test_model, relu, &quot;pred&quot;,256,10)softmax = brew.softmax(test_model,relu,&quot;softmax&quot;)#使用caffe2的accuracy函数计算准确率accuracy = brew.accuracy(test_model, [softmax,labels_test],&quot;accuracy&quot;)</code></pre><p>接下来运行这个测试用的网络并得到准确率</p><pre><code>import numpy as npworkspace.RunNetOnce(test_model.param_init_net)workspace.CreateNet(test_model.net)total_iters = 50accuracy = np.zeros(50)for i in range(total_iters):workspace.RunNet(test_model.net)accuracy[i] = workspace.FetchBlob(&quot;accuracy&quot;)plt.plot(accuracy)print(&quot;test accuracy:{}&quot;.format(accuracy.mean()))</code></pre><img src="/2019/11/24/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C/caffe2_accuracy.png" srcset="undefined" class=""><p>至此，基于MNIST的手写数字识别网络就完成了。下一节我们将进一步了解更加复杂的网络结构，并使用一个新的数据集构建网络。</p><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>简单来说，一张图的每个原色占有一个通道，所以一张以RGB存储的彩色照片就有代表R,G,B的三个通道。MNIST的图像为单色图像，因此只会有一个通道。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>仿射变换即如Ax+b这种对x进行A的线性变换后再根据b将x移动到向量空间中不同的位置。一次仿射变换等价于当前向量空间的更高维的线性变换。例如在二维欧氏平面上进行的仿射变换在三位欧氏空间中即为线性变换。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <categories>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>caffe2</tag>
      
      <tag>DNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch&amp;caffe2 深度学习的魔法 线性回归网络</title>
    <link href="undefined2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/"/>
    <url>2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<p>从这节开始，我们就要正式接触神经网络了。在构造更加复杂的神经网络之前，我们从一个简单的例子开始——线性回归。只要初学过统计甚至使用过一些电子表格软件（如Excel）的人都知道，线性回归可以让计算机在数据点间找到一个规律，并通过一个线性函数表示出来。虽然简单，但这个神经网络已经包含了神经网络必须的要素。在构造网络前，我们先来分析线性回归的模型是什么样的。</p><h1 id="线性回归模型"><a class="markdownIt-Anchor" href="#线性回归模型"></a> 线性回归模型</h1><p>在最简单的线性回归中，我们需要找的是如下函数的参数</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo stretchy="true">^</mo></mover><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><mi>x</mi><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\widehat{y}=w_1x+b_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.865em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.67056em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span class="svg-align" style="width:calc(100% - 0.11112em);margin-left:0.11112em;top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>被称作权重(weight)，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>b</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">b_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>被称作偏差(bias)，这两个值是神经网络的参数。另外两个变量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>是这个模型的输入，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo stretchy="true">^</mo></mover></mrow><annotation encoding="application/x-tex">\widehat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.865em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.67056em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span class="svg-align" style="width:calc(100% - 0.11112em);margin-left:0.11112em;top:-3.43056em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.24em;"><svg width='100%' height='0.24em' viewBox='0 0 1062 239' preserveAspectRatio='none'><path d='M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span></span>是这个模型的输出，即线性回归的预测值。为了能让网络得到正确的预测值，我们需要训练神经网络，即使用一系列已知的输入和输出的关系让神经网络自行找出正确的参数。这个过程通过神经网络反向传播完成。下面我们先简单熟悉一下什么是反向传播。具体的数学定义可以查看<a href="https://en.wikipedia.org/wiki/Backpropagation" target="_blank" rel="noopener">wikipedia</a>介绍和经典的<a href="https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf" target="_blank" rel="noopener">Learning representations by back-propagating errors（通过反向传播误差学习）</a>论文了解。</p><h1 id="反向传播简介"><a class="markdownIt-Anchor" href="#反向传播简介"></a> 反向传播简介</h1><p>反向传播是结合误差分析和微分使神经网络自行学习的方法。我们在这里不会接触任何数学知识，只需有一个最粗浅的认识。对于任何一个神经网络来说，数据在其中可以向两个方向流动：正向和反向。正向即神经网络的推理过程：给出一个输入，数据流经神经网络的整个计算图，然后得出一个输出。例如下面这个神经网络</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/FCNN.png" srcset="undefined" class=""><p>一共有四层。最左侧的叫输入层，最右侧的叫输出层，而中间的叫隐藏层。我们的线性回归网络较这个网络简单的多，只有两层，也就是输入层和输出层。输入层上没有实际的运算，因此我们的网络实际只有一层，所以叫单层神经网络。如下图</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/simplest_net.png" srcset="undefined" class=""><p>是上文中线性回归网络的计算图。图中的圆圈被称作节点或神经元，节点中间的线被称作边。在计算时神经网络会将输入与边上的权重<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>相乘，然后再与节点上的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>b</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">b_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>相加，最后得出一个预测的结果。</p><p>反向传播则更加难懂，它是神经网络的训练过程。简单来说，我们给出一组输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>5</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>9</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">X=\left(\begin{matrix}  1 \\  5 \\  9\end{matrix}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.60004em;vertical-align:-1.55002em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">5</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">9</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span></span></span></span></span>和一组已知的输出<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>5</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>17</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>29</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">y=\left(\begin{matrix}  5 \\  17 \\  29  \end{matrix}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.60004em;vertical-align:-1.55002em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">5</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">9</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span></span></span></span></span>（注意神经网络使用的数据均以张量形式表示），神经网络会使用随机的权重和偏差给出一个预测值（通常是根据神经网络启动时的随机参数产生的），用一个损失函数(loss function)得出网络的预测值和我们提供的真实值差距有多大，然后通过一些微分步骤修正每一个节点和每一条边上的参数，重复这个过程即可得到一个比较合理的参数。当神经网络能够得到一个合理的参数，我们就称网络收敛(converge)。我们给出的这组已知的输入和输出的集合被称作训练集，训练集的输入被称作特征(features)，而输出被称作标签(labels)。</p><p>反向传播的核心在于通过微分修正参数，这个过程可以想象成一个小球在山坡上滚动。它的任务是找到这个山的最低点（即神经网络能够收敛的点）。因为这个球很小，它看不见山的全貌，但是它知道哪里地势高一些，哪里地势低一些。于是它每次就向地势低的地方滚动一小段距离，然后再看看周围哪里地势更低，如此往复就有较大可能找到这个山的最低点。神经网络中这座山的陡峭程度被称作梯度，而小球沿着地势滚动的过程即自动求梯度的过程。神经网络通过自动求梯度可以找到一条收敛可能性较大的道路。这个过程称作梯度下降(Gradient Descent)。</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/gradient_descent.png" srcset="undefined" class=""><center>梯度下降示意图 <a href="https://www.youtube.com/watch?v=5u0jaA3qAGk&feature=youtu.be" target="_blank" rel="noopener">来源</a></center><h1 id="使用pytorch构建网络"><a class="markdownIt-Anchor" href="#使用pytorch构建网络"></a> 使用pytorch构建网络</h1><h2 id="建立训练集"><a class="markdownIt-Anchor" href="#建立训练集"></a> 建立训练集</h2><p>在了解了神经网络的一些基本原理之后，我们可以使用pytorch实际训练一个线性回归网络了。首先我们需要准备的是训练集。通常这是神经网络中最难准备的部分（神经网络使用大量数据才能够应付各种情况）。幸运的是，线性回归的数据集准备很简单，只需要使用numpy生成一些随机数就可以了。</p><p>使用<code>conda activate pytorch</code>激活pytorch环境，在一个你喜欢的目录运行<code>jupyter notebook</code>，jupyter应该会自动打开浏览器,如果没有自动打开，在命令行中也会显示一个网址用来复制粘贴。</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/jupyter.png" srcset="undefined" class=""><p>点击右上角新建一个Python3笔记本，然后运行</p><pre><code>#matplotlib是一个python的绘图库，我们用这个库查看数据的分布情况#%matplotlib inline可以让matplotlib画出的图直接在jupyter中显示%matplotlib inlinefrom IPython import displayfrom matplotlib import pyplot as pltimport torchfrom torch.distributions.normal import Normaltrue_w = 3true_b = 2 #我们使用的线性函数的真实权重与偏差           #即y=3x+2#torch.randn函数使用一个标准正态分布生成随机数（期望值为0，标准差为1）#size定义了生成的张量形状，500表示有500个样本#1表示每个样本有一个输入         features = torch.randn(size=(500,1))#为了增加干扰，加入一些噪声#噪声使用一个标准差为0.1的正态分布生成#torch.distributions.normal.Normal类可以让我们自定义期望值和标准差noise = Normal(loc=0,scale=0.1)#pytorch的张量可以直接与数字（标量）进行运算，效果与广播类似#这一步通过真实的权重与偏差算出特征对应的标签#噪声是一个Normal类的实例，sample方法接受一个size参数，返回一个随机数张量labels = true_w * features + true_b + noise.sample((500,1))</code></pre><p>这样训练集就已经制作完成了，我们可以使用for循环查看输入和输出的对应关系，或者使用matplotlib更加直观的画出线性关系</p><pre><code>#用for循环打印前十个特征和标签for X,y in zip(features[:9],labels[:9]):print(X,y)#用matplotlib画出图像#使用svg画出更加清晰的图display.set_matplotlib_formats('svg')#matplotlib只接受numpy数组#pytorch张量的numpy方法可以将pytorch张量转为numpy数组plt.scatter(features.numpy(), labels.numpy(), 1);</code></pre><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/training_data.png" srcset="undefined" class=""><p>可以看到数据点间的有着较强的线性关系。</p><h2 id="准备数据"><a class="markdownIt-Anchor" href="#准备数据"></a> 准备数据</h2><p>出于性能考虑，神经网络通常不会直接使用500个数据训练，而是每次使用较少的样本（如10个），每个小样本被称作小批量。神经网络会随机从所有数据中取出10个数据，根据这10个数据计算梯度，然后沿着梯度方向下降至最小点。pytorch提供了TensorDataset和DataLoader两个类将刚刚生成的数据转成pytorch使用的数据集。</p><pre><code>from torch.utils.data import TensorDataset, DataLoader#TensorDataset可以将两个第一个维度大小相同的张量合并成一个数据集train_dataset = TensorDataset(features,labels)#DataLoader接受上一步生成的数据集，生成小批量，可以自定义批量大小和数据用完后是否重新排序dataloader = DataLoader(train_dataset,batch_size=10,shuffle=True)</code></pre><p>可以用for循环提取出所有的特征和标签的关系</p><pre><code>for data in dataloader:print(data)</code></pre><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/datasets.png" srcset="undefined" class=""><h2 id="构建网络"><a class="markdownIt-Anchor" href="#构建网络"></a> 构建网络</h2><p>在做好所有的准备工作后，我们终于可以构建这个线性回归网络了。之前讲过神经网络的结构是用计算图表示的，其中会包括一些计算层。pytorch已经预先定义了很多神经网络常用的层，我们只需要调用这些函数就行了。大部分层的定义都在pytorch的nn模块，nn即neural network的缩写，我们先导入这个模块并创建一个网络。</p><pre><code>from torch import nnnet = nn.Sequential(nn.Linear(1,1))</code></pre><p>这就是所有需要做的：nn.Sequential是一个pytorch预定义的模型框架模块，它的功能很简单，只是将所有传入的层头尾相连。nn.Linear是一个线性层，也叫全连接层，在tensorflow等框架中名为Dense，而在其他一些网络框架中称为Affine。它的作用就是将所有的输入乘上自己的权重，加上偏差再输出，即y=wx+b。注意Linear有两个参数，第一个参数是输入的大小，第二个参数是输出的大小。我们的线性回归模型只有一个输入和一个输出，所以两个值均为1。由于输入层没有实际运算，我们只需要一个Linear层就能满足运算需求。</p><p>定义好结构后，我们还需要初始化网络的参数。初始化算法有很多，我们使用简单的正态分布初始化。初始化函数在torch.nn.init中定义。</p><pre><code>def init_weights(m):if type(m) == nn.Linear:nn.init.normal_(m.weight)m.bias.data.fill_(0.01)net.apply(init_weights)</code></pre><p>这里我们定义了一个init_weights函数——这是初始化一个pytorch网络模块的标准做法。其中m参数是网络中的一层，m.weight和m.bias为这一层的权重和偏差，两者均为pytorch张量。nn.init.normal_函数将这层的权重使用正态分布初始化，而m.bias.data.fill_则将bias直接初始化为0.01。net.apply方法将这个初始化函数应用在网络中的每一层上，这样初始化就完成了。</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/net.png" srcset="undefined" class=""><p>在训练前，网络还需要一个损失函数，也就是神经网络判断自己离正确答案有多接近的函数，我们使用比较常用的MSE（均方误差）函数。另外，我们还需要一个梯度下降算法，这里我们使用小批量随机梯度下降算法(SGD)，也就是前文所讲的随机挑选出一小部分样本计算梯度的算法。</p><pre><code>criterion = torch.nn.MSELoss() #均方误差损失函数#SGD算法收集神经网络的所有参数进行学习，lr为学习率#学习率是一个超参数，也就是神经网络以多快的速度学习#超参数是神经网络不能自己学习到的参数，需要人来调整#以前文小球的例子做类比，学习率相当于小球每一步滚多远optimizer = torch.optim.SGD(net.parameters(),lr=0.01)</code></pre><p>全部准备完毕后，我们终于可以开始训练神经网络了。神经网络通常需要将整个训练集循环使用多次才能达到最佳训练效果，每一次循环被称作一代(epoch)，我们让这个网络循环五代。</p><pre><code>for epoch in range(5):loss = 0for data in dataloader:#从dataloader中取数据features, labels = data#将梯度下降算法的梯度清零，每一个小批量的梯度应该独立optimizer.zero_grad()#通过正向传播得出当前网络的输出outputs = net(features)#使用损失函数计算当前输出和真实值（标签）差距loss = criterion(outputs,labels)#根据算出的损失反向传播loss.backward()#最后梯度下降算法更新所有参数optimizer.step()#每运行完一代就显示训练效果print(&quot;epoch {}, loss {}&quot;.format(epoch+1,loss.item()))</code></pre><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/train.png" srcset="undefined" class=""><p>损失不断变小说明网络的输出越来越接近真实值，至此，我们的神经网络就训练成功了。我们来看一看训练的效果。</p><pre><code>#准确的线性函数输入和输出x = [-2,-1.5,-1,-0.5,0,0.5,1,1.5,2]y = list(map(lambda x:3*x+2,x))#生成一些随机x值用于测试神经网络test = torch.randn(size=(50,1))#测试时不需要计算梯度，torch.no_grad关闭梯度计算with torch.no_grad():#通过正向传播得出网络的输出predicted = net(test)#绘图函数plt.plot(x, y, 'go', label='True data', alpha=0.5)plt.plot(test, predicted, '-', label='Predictions', alpha=0.5)plt.legend(loc='best')plt.show();</code></pre><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/test.png" srcset="undefined" class=""><p>可以看到预测值连成的线与实际值相差无几。</p><p>我们也可以直接查看网络的参数。</p><pre><code>#网络可以通过索引获得其中包含的层net[0].weight, net[0].bias</code></pre><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/parameters.png" srcset="undefined" class=""><p>网络的权重为2.9898，偏差为1.9971，与实际值3和2几乎一致。</p><h1 id="使用caffe2构建网络"><a class="markdownIt-Anchor" href="#使用caffe2构建网络"></a> 使用caffe2构建网络</h1><p>##caffe2与pytorch的不同</p><p>caffe2的神经网络构造方法没有pytorch那么直观，这是caffe2和pytorch的设计理念不同造成的。pytorch注重简单灵活，因此它使用命令式编程，所有函数都会像普通的python函数一样执行，可以直接和python的循环搭配使用。但负面作用是pytorch只能动态生成计算图，不能从计算图上进行全局优化，运行较慢。但最新的pytorch引入了JIT编译器，再加上pytorch可以使用高性能的caffe2加速计算，大大提高了运行效率。</p><p>caffe2更加注重效率，因此它包含了大量优化过的操作，并且使用符号式编程，所有的网络中的元素先定义成不同的符号。符号只是个占位符，最后需要编译才能运行。编译时网络编译器可以从全局上优化代码，并生成效率高的静态计算图，但是不能直接使用python提供的一些功能，而是需要使用框架的符号作为替代（在某些网络上，python的循环，条件判断等语句都不能使用，需要用caffe2提供的操作符完成）。因为它编写较为麻烦，大部分caffe2模型都是先在pytorch上构建好然后导出到caffe2上运行。在pytorch1.0发布后，Facebook更是直接将两个框架合二为一，使程序员可以同时享受pytorch的便捷和caffe2的高效。</p><p>因此，这部分内容只是给想要了解caffe2的读者一个参考，也是为了让文章更加完整（同时也有我对caffe2的一点私心）。由于caffe2的API已经停止支持，并且官方的发行版没有包含一些caffe2需要的库（这些库在这个示例中不需要，但是在大部分网络中需要），建议初学者只学习pytorch。</p><h2 id="使用caffe2构建线性回归网络"><a class="markdownIt-Anchor" href="#使用caffe2构建线性回归网络"></a> 使用caffe2构建线性回归网络</h2><p>caffe2的API较为晦涩难懂，且提供多种不同的API，这里我们混合使用API进行实作。本例改编自<a href="https://caffe2.ai/docs/tutorial-MNIST.html" target="_blank" rel="noopener">官网教程</a></p><p>首先我们导入caffe2需要的包，并使用caffe2提供的一个便利工具ModelHelper类创建一个名叫train_model的网络</p><pre><code>from caffe2.python import brew, core, model_helper, optimizer, workspace, net_drawertrain_model = model_helper.ModelHelper(&quot;train_model&quot;)</code></pre><p>ModelHelper创建的模型内置了两个网络——param_init_net和net。param_init_net用于初始化网络中的参数和常量，而net则是真正用于训练的网络。我们在param_init_net中创建三个符号——weights_gt，bias_gt和ONE。</p><pre><code>weights_gt = train_model.param_init_net.GivenTensorFill([],&quot;weight_gt&quot;,shape=[1,1],values=[3.])bias_gt = train_model.param_init_net.GivenTensorFill([],&quot;bias_gt&quot;,shape=[1],values=[2.])ONE = train_model.param_init_net.ConstantFill([], &quot;ONE&quot;, shape=[1], value=1.0)</code></pre><p>gt是ground true的缩写，也就是线性函数的真实参数。ONE是在后面更新梯度时需要用到的一个值。这里我们分别调用了param_init_net的GivenTensorFill方法和ConstantFill方法创建了两个张量和一个常数。注意caffe2创建张量与pytorch有诸多不同之处。首先每一个张量都需要命名，这是为了在生成计算图时方便找到对应的张量在图上的位置，其次我们可以尝试打印出这几个变量：</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/caffe2_variable.png" srcset="undefined" class=""><p>可以看到这几个变量并没有实际存储张量，而只是一个引用。caffe2只会在最后实际生成计算图时才会实际创建这些变量。</p><p>运行</p><pre><code>train_model.param_init_net.Proto()</code></pre><p>可以看到在param_init_net中定义的符号。再次强调这些符号并没有实际生成，caffe2只会存储它们的结构，所有的变量都会在创建计算图时生成。</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/caffe2_init_proto.png" srcset="undefined" class=""><p>在创建完网络需要的常量后，我们在net上创建网络运行时使用的变量</p><pre><code>features = train_model.net.GaussianFill([], &quot;features&quot;, mean=0.0, std=1.0, shape=[10, 1], run_once=0)labels = features.FC([weights_gt,bias_gt],&quot;labels&quot;)noise = train_model.net.GaussianFill([], &quot;noise&quot;, mean=0.0, std=0.1, shape=[10, 1], run_once=0)noise_labels = labels.Add(noise,&quot;noise_labels&quot;)noise_labels = noise_labels.StopGradient([], &quot;noise_labels&quot;)</code></pre><p>这里我们看到caffe2和pytorch又一个不同之处。caffe2的数据生成和计算图融合在一起，而不是像pytorch单独使用DataLoader为网络提供数据。这也是因为静态计算图需要包括网络训练的所有步骤。在这里features是一个大小为(10,1)的张量，里面包含了使用标准正态分布生成的数字。然后在features上调用FC方法（即全连接层，与pytorch的Linear一致）生成对应的标签。最后我们加上噪声，使用labels.Add方法可以将label和noise相加。由于这里的FC层和Add层作用是生成样本，我们不需要反向传播，因此还需要使用StopGradient方法告诉caffe2不需要对此处计算梯度。这样，每一次net运行时，就会生成新的特征和标签用于神经网络训练。</p><p>接下来就是定义网络本身。</p><pre><code>pred = brew.fc(train_model,features,&quot;pred&quot;,dim_in = 1,dim_out = 1)dist = train_model.SquaredL2Distance([noise_labels,pred],&quot;dist&quot;)loss = dist.AveragedLoss([],[&quot;loss&quot;])</code></pre><p>这里我们使用caffe2的一个比较高级的API brew生成一个全连接层。brew可以省去自己创建模型的权重和偏差的麻烦，它会掉用初始化算法对权重和偏差初始化。我们只需要定义输入和输出的数量，在这里都为1。接下来是定义损失函数，这里的损失函数和我们在pytorch中使用的MSELoss一样，平方和也被称作L2范数，也就是SquaredL2Distance中的L2。由于caffe2没有提供MSE函数，我们需要先计算平方和再取平均值。</p><p>由于caffe2最终能生成静态图，我们可以用net_drawer模块看到计算图的样子，我们调用这个函数查看一下</p><pre><code>from IPython import displaygraph = net_drawer.GetPydotGraph(train_model.Proto().op, &quot;train&quot;, rankdir=&quot;LR&quot;)display.Image(graph.create_png(), width=800)</code></pre><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/computational_graph.png" srcset="undefined" class=""><p>可以看到我们创建的bias_gt等变量都已经在图上显示出来了。由于caffe2会自动优化神经网络，相较于pytorch而言debug较难，检查计算图有时会很有帮助。</p><p>接下来就是加上梯度下降算法</p><pre><code>train_model.AddGradientOperators([loss])ITER = brew.iter(train_model,&quot;iter&quot;)LR = train_model.LearningRate(ITER, &quot;LR&quot;, base_lr=0.01, policy=&quot;step&quot;, stepsize=1, gamma=0.999)for param in train_model.params:param_grad = train_model.param_to_grad[param]train_model.WeightedSum([param, ONE, param_grad, LR], param)</code></pre><p>我们使用loss计算梯度，ITER是用于追踪迭代情况的变量，而LR设定了梯度下降算法的一些超参数。这里除了之前看到的base_lr是学习率以外，gamma是一个衰减率，我们在这里先不用管。在设定好学习率后，我们还需要设定更新网络参数的算法。这里的算法是<code>param = param + param_grad * LR</code>，param是参数，param_grad是反向传播后计算出的梯度，LR是学习率，即要往梯度的方向走多远。使用for循环可以将网络中的参数一一提取出来，然后使用param_to_grad获取计算图上反向传播梯度的符号，再使用WeightedSum设定更新算法。</p><p>最后我们进行实际的训练</p><pre><code>workspace.RunNetOnce(train_model.param_init_net)workspace.CreateNet(train_model.net)total_iters = 500loss = [0 for i in range(500)]for i in range(total_iters):workspace.RunNet(train_model.net.Proto().name)loss[i] = workspace.FetchBlob('loss')loss</code></pre><p>我们一共迭代500次，使用lost数组记录损失函数的值，然后显示出来。</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/result.png" srcset="undefined" class=""><p>我们也可以把损失值画出来</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/lost_plot.png" srcset="undefined" class=""><p>最后查看一下训练出的模型的参数</p><img src="/2019/11/21/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BD%91%E7%BB%9C/caffe2_parameters.png" srcset="undefined" class=""><p>可以看到神经网络的参数和实际参数基本一致</p><p>到这里我们的第一个神经网络就全部完成了，虽然这个例子很简单，但它囊括了神经网络的各种要素，在下一节我们将构建一个能够识别手写数字的网络，使用到的数据集便是之前提到的MNIST数据集。</p>]]></content>
    
    
    <categories>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>caffe2</tag>
      
      <tag>基础</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch&amp;caffe2 深度学习的魔法 张量</title>
    <link href="undefined2019/11/19/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%BC%A0%E9%87%8F/"/>
    <url>2019/11/19/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%BC%A0%E9%87%8F/</url>
    
    <content type="html"><![CDATA[<p>前面讲过，本质上神经网络是一个巨大的数学机器，而驱动这个数学机器的核心原理主要有三个：线性代数，概率论和微分。神经网络使用线性代数操作数据，使用自动求导修正自己的“认知”，最后根据概率论得出一个合理的结果。自动求导和求概率的问题框架都提供了强大的工具自动完成，而为神经网络准备合适的数据则是开发神经网络的重点问题。本节我们先来认识神经网络使用的基本数据结构——张量。</p><h1 id="张量简介"><a class="markdownIt-Anchor" href="#张量简介"></a> 张量简介</h1><p><em>简单起见，这节内容只会讲一些最基本的知识，并不是严格的数学理论和推导，下列定义在数学上不严谨或有误，但是不影响在神经网络中使用张量</em></p><p>在计算机科学中，我们可以简单的把张量认为是一个可以无限扩张的容器，例如二维表就是一种张量，也就是说它有一个纵轴和横轴，例如：</p><table><thead><tr><th>姓名</th><th>年龄</th><th>班级</th></tr></thead><tbody><tr><td>张三</td><td>17</td><td>高三1班</td></tr><tr><td>李四</td><td>19</td><td>高三2班</td></tr></tbody></table><p>这张表可以被称作一个二维张量，实际有数据的尺寸是(2,3)，我们可以命名为（人数，详细信息）。虽然看上去是两行三列，但是张量可以通过操作转换行和列的关系，因此我们用一对数字表示它的尺寸。我们可以用坐标获取表中任意的数据，例如(1,2)代表了17。</p><p>表非常有用，只需要一个索引就可以取出所有有关的数据（例如取第一行结果是(张三,17,高三一班)），但是如果我们需要存储两个学校的数据，那么用表就有些吃力。一种解决方式是将表变成(2,4)大小，然后学校单独存储，但是这样如果需要按学校处理数据就需要先找出所有同学校的人。需要注意的是张量并不是SQL或类似数据库的表，所有查询都是使用数字索引实现，因此找出属于同一个学校的数据会变的异常困难。更好的方法是将不同的学校分到不同的表里，然后将它们放入一个三维张量，这样就得到了一个大小为(2,2,3)的张量，我们也可以给这个张量的每个维度命名：（学校，人数，详细信息）。它可以想象成是一个由1x1x1的立方体组成的一个2x2x3的长方体，每一个立方体都代表一个值。不断增加张量的维度就可以容纳更多数据，并可以通过数字索引取得对应的值。</p><h1 id="在python中表示张量"><a class="markdownIt-Anchor" href="#在python中表示张量"></a> 在python中表示张量</h1><p>在python中有多种工具可以创建一个张量，首先我们使用numpy——老牌的科学计算包。numpy的功能很多，我们将只关注其中与张量有关的部分。</p><p>首先使用熟悉的终端打开python，然后运行</p><pre><code>&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; x=np.ones((2,3))&gt;&gt;&gt; xarray([[1., 1., 1.],   [1., 1., 1.]])</code></pre><p>numpy.ones函数创建一个张量（numpy中称为array，即数组，这篇文章中使用张量称呼它），然后将每一个值初始化为1。现在我们已经有了一个张量，我们看一看它的一些属性和方法。</p><pre><code>&gt;&gt;&gt; x.shape(2,3)&gt;&gt;&gt; x.size6&gt;&gt;&gt; x.resize(10)&gt;&gt;&gt; xarray([1., 1., 1., 1., 1., 1., 0., 0., 0., 0.])&gt;&gt;&gt; x.shape(1,10)&gt;&gt;&gt; x.reshape((2,5))array([[1., 1., 1., 1., 1.],   [1., 0., 0., 0., 0.]])</code></pre><p>一个张量的shape代表它的形状，而size代表了它包含几个元素。因此resize会让张量变成一个一维张量（一般叫向量）并同时增加它包含的元素数量；而reshape不会改变元素数量，但是会改变形状。</p><p>张量间也可以有一些运算，一般来说两个张量要大小一致才能计算，例如：</p><pre><code>&gt;&gt;&gt; X = np.array([[1,5,2,6],[2,7,2,9]])#np.array函数可以使用python数组创建张量&gt;&gt;&gt; Y = np.array([[2,7,9,5],[1,8,4,6]])&gt;&gt;&gt; X+Yarray([[ 3, 12, 11, 11],   [ 3, 15,  6, 15]])&gt;&gt;&gt; X-Yarray([[-1, -2, -7,  1],   [ 1, -1, -2,  3]])&gt;&gt;&gt; X*Yarray([[ 2, 35, 18, 30],   [ 2, 56,  8, 54]])&gt;&gt;&gt;X/Yarray([[0.5       , 0.71428571, 0.22222222, 1.2       ],   [2.        , 0.875     , 0.5       , 1.5       ]])</code></pre><p>使用加减乘除运算符可以对张量按元素计算，也就是对应位置上的元素会相加，相减，相乘或相除。</p><p>numpy的张量（包括pytorch的张量）也支持形状不同的张量进行加减乘除运算，此时numpy会复制原有的值让张量的大小变得一致，这个机制叫做广播：</p><pre><code>&gt;&gt;&gt; A = np.arange(3).reshape((3,1)) #arange函数会生成[0,1,2,3,4,5]这样的一维张量&gt;&gt;&gt; B = np.arange(4).reshape((1,4))&gt;&gt;&gt; A+Barray([[0, 1, 2, 3],   [1, 2, 3, 4],   [2, 3, 4, 5]])</code></pre><p>在这里A的第一列被复制了4遍，B的第一行被复制了三遍从而形成了两个(4,3)的张量，这时就可以进行加法运算了。</p><p>除此之外还可以使用np.exp函数进行以e为底的指数函数运算，例如</p><pre><code>&gt;&gt;&gt; np.exp(X)array([[2.71828183e+00, 1.48413159e+02, 7.38905610e+00, 4.03428793e+02],   [7.38905610e+00, 1.09663316e+03, 7.38905610e+00, 8.10308393e+03]])</code></pre><p>之前讲过，张量可以用一些操作改变行和列的顺序，这个操作叫作转置，使用T表示</p><pre><code>&gt;&gt;&gt; X.T&gt;&gt;&gt; array([[1, 2],   [5, 7],   [2, 2],   [6, 9]])</code></pre><p>最后还要讲到一个张量的特有的运算：点乘。点乘是将一个张量的第一个或多个维度的数据和另一个张量的最后一个或多个维度的数据对应相乘并相加，这是一个比较难懂的概念，以二位张量为例，通常二位张量的第一个维度是行，最后一个维度是列，所以相乘过程如下图所示</p><img src="/2019/11/19/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%BC%A0%E9%87%8F/dot.png" srcset="undefined" class=""><p>在numpy中如下操作</p><pre><code>&gt;&gt;&gt; np.dot(X,Y.T)array([[ 85,  85],   [116, 120]])</code></pre><p>原本X和Y均为(2,4)大小的张量，Y转置后变为(4,2)张量，第一列的值为[2,7,9,5]，X的第一行值为[1,5,2,6]，计算<code>1*2+5*7+2*9+5*6</code>得85。</p><p>最后需要讲的是张量的索引。张量的索引与python的列表下标获取方式类似，都是从0开始，<code>:</code>可以用于切片，如下所示</p><pre><code>&gt;&gt;&gt; X[1]array([2, 7, 2, 9])&gt;&gt;&gt; X[1,2]2&gt;&gt;&gt; X[1:]array([[2, 7, 2, 9]])</code></pre><h1 id="pytorch中的张量"><a class="markdownIt-Anchor" href="#pytorch中的张量"></a> pytorch中的张量</h1><p>由于numpy的巨大影响力，很多神经网络框架的python张量API都类似于numpy，caffe2直接使用numpy处理数据，直到开始构建神经网络时才会转成caffe2自己的张量格式，pytorch则是提供了与numpy类似的API，请直接看下面的演示。</p><pre><code>&gt;&gt;&gt; import torch&gt;&gt;&gt; x = torch.ones((2,3))&gt;&gt;&gt; xtensor([[1., 1., 1.],    [1., 1., 1.]])&gt;&gt;&gt; x.shapetorch.Size([2, 3])&gt;&gt;&gt; x.size()torch.Size([2, 3]) #注意pytorch不会显示元素数量，因为神经网络并不关心张量中有几个元素&gt;&gt;&gt; x.reshape((1,6))tensor([[1., 1., 1., 1., 1., 1.]])&gt;&gt;&gt; x.resize(1,6)tensor([[1., 1., 1., 1., 1., 1.]]) #同理resize和reshape功能一样，注意reshape接受元组而resize接受两个参数&gt;&gt;&gt; X = torch.tensor([[1,5,2,6],[2,7,2,9]])&gt;&gt;&gt; Y = torch.tensor([[2,7,9,5],[1,8,4,6]])&gt;&gt;&gt; X+Ytensor([[ 3, 12, 11, 11],    [ 3, 15,  6, 15]])&gt;&gt;&gt; X-Ytensor([[-1, -2, -7,  1],    [ 1, -1, -2,  3]])&gt;&gt;&gt; X*Ytensor([[ 2, 35, 18, 30],    [ 2, 56,  8, 54]])&gt;&gt;&gt; X/Ytensor([[0, 0, 0, 1],    [2, 0, 0, 1]]) #注意此处pytorch不会自动把整数转成浮点数    #因为pytorch的张量有固有的类型&gt;&gt;&gt; A = torch.arange(3).reshape((3,1))&gt;&gt;&gt; B = torch.arange(4).reshape((1,4))&gt;&gt;&gt; A+Btensor([[0, 1, 2, 3],    [1, 2, 3, 4],    [2, 3, 4, 5]])&gt;&gt;&gt; torch.exp(X)RuntimeError: exp_vml_cpu not implemented for 'Long'#torch.exp及大部分函数不支持LongTensor类型（即全部由整数构成的张量）#因此我们需要将X和Y转成FloatTensor#强制要求FloatTensor原因是神经网络参数均为浮点数，若使用LongTensor#神经网络的自由度将大大缩小，这也是以后需要注意的地方&gt;&gt;&gt; X = X.type(torch.FloatTensor)&gt;&gt;&gt; Y = Y.type(torch.FloatTensor)&gt;&gt;&gt; torch.exp(X)tensor([[2.7183e+00, 1.4841e+02, 7.3891e+00, 4.0343e+02],    [7.3891e+00, 1.0966e+03, 7.3891e+00, 8.1031e+03]])&gt;&gt;&gt; X.Ttensor([[1., 2.],    [5., 7.],    [2., 2.],    [6., 9.]])#pytorch使用tensordot而不是dot对张量进行点乘，dims参数指定#有几个维度参与点乘（X从前往后第d个，Y从后往前第D个）#一般二维张量是1，三维张量是2#dims也可以使用两个list指定哪两个维度进行点乘&gt;&gt;&gt; torch.tensordot(X,Y.T,dims=1)tensor([[ 85.,  85.],    [116., 120.]])&gt;&gt;&gt; X[1]tensor([2., 7., 2., 9.])&gt;&gt;&gt; X[1,2]tensor(2.)&gt;&gt;&gt; X[1:]tensor([[2., 7., 2., 9.]])</code></pre><p>到此，张量的基本操作就讲解的差不多了，接下来我们就要真正的开始使用框架构造我们的第一个神经网络——线性回归网络。</p>]]></content>
    
    
    <categories>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>caffe2</tag>
      
      <tag>基础</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch&amp;caffe2 深度学习的魔法 安装pytorch</title>
    <link href="undefined2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/"/>
    <url>2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/</url>
    
    <content type="html"><![CDATA[<p>“工欲善其事，必先利其器”。在正式接触神经网络的种种用法前，首先要安装好pytorch和相关的运行环境。本系列中用到的语言均为python，并使用pytorch和caffe2的python API实作。可能有一些读者阅读本系列前系统中已经安装了一个或多个python环境，但是通常使用的python环境缺少一些科学计算所必须的运行库。为了省却自己安装库的麻烦，在这里我们使用anaconda或miniconda安装pytorch。</p><h1 id="安装anacondaminiconda"><a class="markdownIt-Anchor" href="#安装anacondaminiconda"></a> 安装anaconda/miniconda</h1><p>anadconda是一个专门为科学计算设计的python发行版，它自带180余个常用科学软件包的一个名叫conda的环境管理器。conda能够安装绝大部分python科学计算包，同时也具有管理python环境的功能。为了不让pytorch的一些包和日常开发用的其他模块包，我们最好使用conda新建一个干净的python环境并在里面安装pytorch。</p><p>由于anaconda自带的很多包我们实际用不上，而且全部安装比较占用空间（大约有450MB），因此anaconda提供了另一个精简化的选择：miniconda。miniconda只包含了一个python运行时和一个conda管理器，占用的空间较小，同时也可以更灵活的配置需要的包，miniconda与anaconda安装方式相同，因此在下文中我会介绍miniconda安装方法，并附上anaconda下载地址。</p><h2 id="在windows上安装miniconda"><a class="markdownIt-Anchor" href="#在windows上安装miniconda"></a> 在Windows上安装miniconda</h2><p>1.在 <a href="https://docs.conda.io/en/latest/miniconda.html" target="_blank" rel="noopener">https://docs.conda.io/en/latest/miniconda.html</a> 处下载Windows版本的miniconda，如无特殊理由请选择Python3.7版，并根据自己的系统选择32位或64位。</p><p>2.双击安装包，打开界面如下所示</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/windows-step2.png" srcset="undefined" class=""><p>3.点击下一步，保持默认安装选项不变，选择安装路径（推荐安装在C盘）</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/windows-step3.png" srcset="undefined" class=""><p>4.高级选项中第一个选项是将miniconda加入环境变量，加入后可以直接从cmd或powershell使用miniconda命令。如果曾经没有安装过其他版本的python可以选择该选项，否则可能会扰乱其他依赖python的程序的正常运行。官方推荐不勾选该选项而是从开始菜单运行miniconda。第二个选项是将miniconda附带的python3.7注册为系统默认python3.7版本，勾选后IDE可以自动检测到miniconda，否则需要自己配置miniconda的运行路径。在此我们保持默认配置：第一个不勾选，第二个勾选。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/windows-step4.png" srcset="undefined" class=""><p>5.安装程序会自动进行安装，最后弹出安装完成界面。然后从开始菜单中选择自己喜欢的终端程序（cmd或powershell）就可以开始使用了。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/windows-step5.png" srcset="undefined" class=""><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/miniconda.png" srcset="undefined" class=""><h2 id="在macos上安装miniconda"><a class="markdownIt-Anchor" href="#在macos上安装miniconda"></a> 在MacOS上安装miniconda</h2><p>1.在 <a href="https://docs.conda.io/en/latest/miniconda.html" target="_blank" rel="noopener">https://docs.conda.io/en/latest/miniconda.html</a> 处下载MacOS版本的miniconda，如无特殊理由请选择Python3.7版，注意选择pkg版以使用图形安装器（名字为Miniconda3 MacOSX 64-bit pkg）。</p><p>2.按住option打开安装包（sierra以上）或直接打开（sierra以下），进入图形安装界面。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/mac-step2.png" srcset="undefined" class=""><p>3.保持默认配置并安装，其中可能会要求某些文件夹权限，请注意确认。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/mac-step3.png" srcset="undefined" class=""><p>4.等待弹出安装完成界面，此时打开终端即可使用conda命令。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/mac-step4.png" srcset="undefined" class=""><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/mac-miniconda.png" srcset="undefined" class=""><h2 id="在linux上安装miniconda"><a class="markdownIt-Anchor" href="#在linux上安装miniconda"></a> 在Linux上安装miniconda</h2><p>1.在 <a href="https://docs.conda.io/en/latest/miniconda.html" target="_blank" rel="noopener">https://docs.conda.io/en/latest/miniconda.html</a> 处下载Linux版本的miniconda，如无特殊理由请选择Python3.8版，并根据自己的系统选择32位或64位（此处使用WSL ubuntu演示）。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/linux-step1.png" srcset="undefined" class=""><p>2.使用<code>chmod +x Miniconda3-latest-Linux-x86_64.sh</code>添加执行权限，然后<code>./Miniconda3-latest-Linux-x86_64.sh</code>运行安装脚本。</p><p>3.按屏幕提示按回车键，然后打yes同意协议，最后按回车安装，或按需要更改安装目录后安装。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/linux-eula.png" srcset="undefined" class=""><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/linux-install.png" srcset="undefined" class=""><p>4.安装结束后会询问是否运行conda init。conda init是用于在当前shell中初始化conda环境的命令。运行该命令可以更方便的使用miniconda。</p><p>5.重启当前shell，如果运行了conda init在提示符最前端应该有(base)字样，如果没有运行conda init需要使用eval “$(/root/miniconda3/bin/conda shell.YOUR_SHELL_NAME hook)”（此处YOUR_SHELL_NAME改为当前shell的名称，如bash,zsh,fish等）命令启动conda。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/linux-finish.png" srcset="undefined" class=""><p>以上为在不同系统中安装miniconda的方法。安装完整的anaconda流程一致，只需在<a href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener">https://www.anaconda.com/distribution/</a>下载安装包即可。注意选择和自己系统对应的版本。</p><h1 id="使用conda安装pytorch"><a class="markdownIt-Anchor" href="#使用conda安装pytorch"></a> 使用conda安装pytorch</h1><p>在安装好miniconda后安装pytorch就很简单了。首先为了防止干扰到其他python环境，我们使用<code>conda create --name pytorch</code>创建一个干净的python环境安装pytorch，然后运行<code>conda activate pytorch</code>进入这个新的环境。运行后前面括号里的base变成了pytorch。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/env-change.png" srcset="undefined" class=""><p>接下来直接运行<code>conda install pytorch</code>conda就会自动安装pytorch和所有依赖。安装结束后，运行python，尝试<code>import torch</code>，如果能正常执行那说明就安装成功了。</p><h1 id="编译安装pytorch"><a class="markdownIt-Anchor" href="#编译安装pytorch"></a> 编译安装pytorch</h1><p>由于caffe2的API在pytorch1.0发布后已经停止支持，并且caffe2与pytorch已经合成了一个包，所以caffe2的一些库不再包含在conda的pytorch包里。为了正常使用caffe2我们需要自行编译pytorch。编译过程同样需要在conda环境中进行。具体编译过程由于不同系统差异较大，请查看<a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">https://github.com/pytorch/pytorch</a>的官方指南，在编译时需要额外设置<code>USE_LMDB</code>和<code>USE_LEVELDB</code>两个环境变量为ON以安装caffe2必须的数据库读取库，设置<code>USE_OPENCV</code>安装OPENCV支持（OPENCV需要额外安装），另外还要设置<code>BUILD_BINARY</code>编译一些常用工具。安装完成后再运行<code>conda install future protobuf six pyyaml pydot</code>安装caffe2依赖的额外包才能使用。全部安装完成后启动python并尝试运行<code>from caffe2.python import core</code>，如果没有报错则安装成功。</p><h1 id="安装jupyter"><a class="markdownIt-Anchor" href="#安装jupyter"></a> 安装jupyter</h1><p>在结束前，我们还需要安装jupyter。jupyter是一个强大的python记事本，可以在浏览器中方便地调试python代码，查看图表，甚至播放声音和视频。jupyter也是conda支持的软件包之一，所以只需要运行<code>conda install jupyter</code>即可安装。</p><p>安装结束后，输入<code>jupyter notebook</code>命令就会运行一个jupyter服务器，并自动打开本地的浏览器，界面如下。默认打开文件浏览器会显示运行jupyter的目录的所有文件。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/jupyter-index.png" srcset="undefined" class=""><p>点击右上角的new，新建一个python3记事本，然后尝试导入pytorch和caffe2。注意一个单元中可以输入多行代码，最后按shift+回车执行整个单元。</p><img src="/2019/11/18/pytorch-caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%AE%89%E8%A3%85pytorch/jupyter-notebook.png" srcset="undefined" class=""><p>到此为止，pytorch和caffe2已经可以正常使用了，下一节将会讲述神经网络的基础数学知识，这对构建一个成功的神经网络至关重要。</p>]]></content>
    
    
    <categories>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>caffe2</tag>
      
      <tag>基础</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch&amp;caffe2 深度学习的魔法 前言</title>
    <link href="undefined2019/11/16/pytorch&amp;caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%89%8D%E8%A8%80/"/>
    <url>2019/11/16/pytorch&amp;caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%89%8D%E8%A8%80/</url>
    
    <content type="html"><![CDATA[<p>自计算机被发明以来，人们一直幻想着它有朝一日能有自己的思想，帮助人们完成各种任务。这种幻想的产物被称作人工智能（Artificial Intelligence）。为此一代又一代的计算机科学家投入了大量的时间和精力去研究人工智能：图灵提出了<a href="https://zh.wikipedia.org/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95" target="_blank" rel="noopener">图灵测试</a>对计算机的思考能力进行评定，到使用知识库和推理引擎的专家系统的诞生<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，又有能让计算机自己学习的机器学习算法的诞生，直至今天我们有了强大的运算能力和完备的算法，我们终于可以一窥深度学习的奥秘。尽管深度学习离科学家所设想的“能思考的机器”还差的很远，但它已足以解决很多曾经计算机无法独自解决的问题。</p><p>这个系列的主题是深度学习的魔法，深度学习是机器学习的一个分支，它基于人工神经网络（ANN）对数据进行学习并作出自己的推演。虽然神经网络和深度学习是最近五年才变得火热，它的历史其实非常悠久。今天的神经网络依然依赖于P. Werbos在1974年提出的反向传播算法，而第一个将它发扬光大的则是卷积网络之父——杨立昆（Yann LeCun）。他在1987年依据反向传播算法制作出了一个可以识别手写的邮政数字的网络，而他使用的MNIST数据集至今仍是神经网络的Hello World级别的入门教材。</p><p>机器学习顾名思义，是能够让计算机通过学习已有的知识去推理未知的事物的过程。从简单的垃圾邮件分类到复杂的AlphaGo，计算机都在通过学习解决实际问题。而正如上文所述，深度学习基于人工神经网络：一个模仿大脑结构的庞大的数学机器。它可以通过学习大量的数据扩充自己的知识储备，然后在未知的数据上得出自己的结论。下面这张图可以大致描述神经网络的工作过程。</p><img src="/2019/11/16/pytorch&caffe2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AD%94%E6%B3%95-%E5%89%8D%E8%A8%80/lgconn.png" srcset="undefined" class=""><p>在近年的演化中，人们开发出各种网络结构和训练方法让神经网络能够高效率地学习的同时保持高正确率，神经网络框架的进步和支持神经网络训练的云平台的出现也让原本难以构造和训练的神经网络变得更加容易开发，使更多构想能够成为现实。</p><h1 id="初识pytorch和caffe2"><a class="markdownIt-Anchor" href="#初识pytorch和caffe2"></a> 初识pytorch和caffe2</h1><p>在神经网络高速发展的今天，各种各样构造神经网络的框架也涌现出来。这些框架极大的降低了构建和训练神经网络的门槛。这些框架将常用的神经网络的基本元件和操作使用C++编写，并开放API供脚本语言（通常是python）调用。这种方式使我们不需要关心底层具体的数学运算，只需要根据自己的需要组装神经网络并调用训练函数就能得到自己的神经网络模型。比较主流的神经网络框架有Google支持的tensorflow和它的API Keras，亚马逊支持的mxnet和它的API gluon，微软支持的CNTK和我们的主角————Facebook支持的pytorch和caffe2。</p><p>pytorch和caffe2分别来自于两个元老级框架：torch和caffe。两者能力各有千秋：pytorch的编码风格更加容易被人们接受，也更容易开发和调试，但效率不如caffe2高；caffe2的编码风格更加晦涩，但是运行效率十分优秀。因此facebook在推出pytorch1.0时，合并了这两个框架，并推荐使用pytorch的API进行开发。为了让体现这两个框架的不同之处，在本系列文章中同一个范例将使用这两个框架分别编写，最后也会给出一个能够在这两个框架间共享同一个模型的方法。由于caffe2的API已经被弃用，这篇文章将主要说明更简单的pytorch写法，如对caffe2有兴趣可以对比查看。</p><h1 id="这个系列会有什么"><a class="markdownIt-Anchor" href="#这个系列会有什么"></a> 这个系列会有什么</h1><p>在这个系列中，我们会从神经网络的一些基础数学知识讲起，并逐步深入，涵盖以下内容</p><ul><li>安装并配置pytorch</li><li>认识张量</li><li>认识神经网络的不同学习方法</li><li>构建一个识别MNIST的全连接网络</li><li>认识计算机视觉和卷积神经网络</li><li>认识自然语言处理和循环神经网络</li><li>使用torchaudio处理音频</li><li>认识生成对抗网络和它的作用</li><li>认识自动编码解码器和其他无监督学习算法</li><li>认识强化学习</li><li>认识transformers——最新的神经网络训练技术</li><li>怎样部署pytorch，并加快运行速度</li><li>怎样在caffe2和pytorch间转换</li></ul><p>训练神经网络需要大量的时间和耐心的调试，因此不要急于求成，一步一步构建自己的神经网络吧。</p><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>知识库是一个精心编写的“真理”数据库，推理引擎是根据知识库给出的真理进行推理的软件。如动物会动，猫是动物是两条真理，推理引擎据此可得出猫会动。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <categories>
      
      <category>神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>caffe2</tag>
      
      <tag>前言</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>